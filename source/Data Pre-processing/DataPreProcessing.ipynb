{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc65abe2",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bca97f",
   "metadata": {},
   "source": [
    "### **I. Import th∆∞ vi·ªán**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3eb3d6",
   "metadata": {},
   "source": [
    "### **II. N·ªëi c√°c file csv thu th·∫≠p ƒë∆∞·ª£c th√†nh m·ªôt file duy nh·∫•t**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc46af",
   "metadata": {},
   "source": [
    "Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n folder ch·ª©a c√°c file csv input v√† t√™n file csv output sau khi n·ªëi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bc041",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"input\"  \n",
    "OUTPUT_FOLDER = \"output\"\n",
    "RAW_FILENAME = \"football_players_raw_dataset.csv\"\n",
    "FINAL_FILENAME = \"football_players_dataset.csv\"\n",
    "\n",
    "RAW_OUTPUT_FILE = os.path.join(OUTPUT_FOLDER, \"football_players_raw_dataset.csv\")\n",
    "FINAL_OUTPUT_FILE = os.path.join(OUTPUT_FOLDER, \"football_players_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv(folder_path, output_folder, output_filename, drop_duplicate=True):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    if not all_files:\n",
    "        print(\"Not found any CSV files in the folder.\")\n",
    "        return\n",
    "    \n",
    "    dfs = []\n",
    "\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            print(f\"Loaded: {file} ({len(df)} rows)\")\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Read error for file {file}: {e}\")\n",
    "\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    if drop_duplicate:\n",
    "        before = len(merged_df)\n",
    "        merged_df = merged_df.drop_duplicates(subset=\"player_id\", keep=\"last\")\n",
    "        after = len(merged_df)\n",
    "        print(f\"Removed {before - after} duplicates\")\n",
    "\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Merged file saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_csv(INPUT_FOLDER, OUTPUT_FOLDER, RAW_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826171b2",
   "metadata": {},
   "source": [
    "### **III. Ti·ªÅn x·ª≠ l√≠ d·ªØ li·ªáu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92cf1c",
   "metadata": {},
   "source": [
    "#### **1. ƒê·ªçc v√† kh√°m ph√° d·ªØ li·ªáu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b98d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RAW_OUTPUT_FILE)\n",
    "print(f\"\\nT·∫≠p d·ªØ li·ªáu: {df.shape[0]} players, {df.shape[1]} features\")\n",
    "\n",
    "\n",
    "print(\"\\nTh√¥ng tin c∆° b·∫£n:\")\n",
    "print(f\"   - Gi√° tr·ªã thi·∫øu (Missing values): {df.isnull().sum().sum():,} cells\")\n",
    "print(f\"   - B·ªô nh·ªõ s·ª≠ d·ª•ng (Memory usage): {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a40a0",
   "metadata": {},
   "source": [
    "#### **2. Ph√¢n lo·∫°i v·ªã tr√≠ c·∫ßu th·ªß**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485119b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_position(pos):\n",
    "    \"\"\"Ph√¢n lo·∫°i v·ªã tr√≠ c·∫ßu th·ªß th√†nh 4 nh√≥m ch√≠nh\"\"\"\n",
    "    if pd.isna(pos):\n",
    "        return 'UNKNOWN'\n",
    "    pos = str(pos).upper()\n",
    "    if 'GK' in pos:\n",
    "        return 'GK'\n",
    "    elif any(x in pos for x in ['DF', 'CB', 'LB', 'RB', 'WB']):\n",
    "        return 'DF'\n",
    "    elif any(x in pos for x in ['MF', 'CM', 'DM', 'AM']):\n",
    "        return 'MF'\n",
    "    elif any(x in pos for x in ['FW', 'ST', 'CF', 'LW', 'RW']):\n",
    "        return 'FW'\n",
    "    return 'UNKNOWN'\n",
    "\n",
    "df['position_category'] = df['position'].apply(classify_position)\n",
    "\n",
    "print(\"\\nPh√¢n b·ªë v·ªã tr√≠:\")\n",
    "for pos, count in df['position_category'].value_counts().items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   {pos:8s}: {count:5,} c·∫ßu th·ªß ({pct:5.1f}%)\")\n",
    "\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng theo v·ªã tr√≠\n",
    "counts = df['position_category'].value_counts()\n",
    "percentages = counts / len(df) * 100\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì\n",
    "plt.figure(figsize=(7, 4))\n",
    "bars = plt.bar(\n",
    "    counts.index,\n",
    "    counts.values,\n",
    "    color=['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974']\n",
    ")\n",
    "\n",
    "# Ghi ch√∫ s·ªë l∆∞·ª£ng + %\n",
    "for bar, count, pct in zip(bars, counts.values, percentages.values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"{count}\\n({pct:.1f}%)\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Position Category\")\n",
    "plt.ylabel(\"Number of Players\")\n",
    "plt.title(\"Distribution of Player Positions\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6017af9",
   "metadata": {},
   "source": [
    "#### **3. Ph√¢n t√≠ch Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_analysis = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Pct': (df.isnull().sum().values / len(df) * 100)\n",
    "})\n",
    "missing_analysis['Data_Type'] = missing_analysis['Column'].apply(lambda x: str(df[x].dtype))\n",
    "missing_analysis = missing_analysis.sort_values('Missing_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nC√ÅC C·ªòT C√ì MISSING > 5%:\")\n",
    "print(\"-\" * 80)\n",
    "high_missing = missing_analysis[missing_analysis['Missing_Pct'] > 5]\n",
    "\n",
    "for idx, row in high_missing.head(20).iterrows():\n",
    "    status = \"üî¥\" if row['Missing_Pct'] > 80 else \"üü°\" if row['Missing_Pct'] > 50 else \"üü¢\"\n",
    "    print(f\"{status} {row['Column']:45s}: {row['Missing_Pct']:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2d2a9",
   "metadata": {},
   "source": [
    "C√°c c·ªôt c√≥ t·ª∑ l·ªá missing > 95% ch·ªß y·∫øu l√† ch·ªâ s·ªë ƒë·∫∑c th√π cho TH·ª¶ M√îN, ch·ªâ xu·∫•t hi·ªán khi c·∫ßu th·ªß thi ƒë·∫•u ·ªü v·ªã tr√≠ GK:\n",
    "\n",
    "- Ch·ªâ s·ªë c·ª©u thua & b√†n thua\n",
    "\n",
    "   - saves_per90: S·ªë pha c·ª©u thua m·ªói 90 ph√∫t\n",
    "\n",
    "   - save_percentage: T·ª∑ l·ªá c·ª©u thua\n",
    "\n",
    "   - shots_on_target_against_per90: S·ªë c√∫ s√∫t tr√∫ng ƒë√≠ch ph·∫£i ƒë·ªëi m·∫∑t\n",
    "\n",
    "   - goals_against_per90: S·ªë b√†n thua m·ªói 90 ph√∫t\n",
    "\n",
    "   -  clean_sheet_pct: T·ª∑ l·ªá gi·ªØ s·∫°ch l∆∞·ªõi\n",
    "\n",
    "- Post-shot xG & ph·∫°t ƒë·ªÅn\n",
    "\n",
    "   - psxg_per_shot: Post-shot xG tr√™n m·ªói c√∫ s√∫t ƒë·ªëi m·∫∑t\n",
    "\n",
    "   - psxg_ga_per90: Post-shot xG b√†n thua m·ªói 90 ph√∫t\n",
    "\n",
    "   - penalty_save_pct: T·ª∑ l·ªá c·∫£n ph√° ph·∫°t ƒë·ªÅn\n",
    "\n",
    "- Ki·ªÉm so√°t kh√¥ng gian & b√≥ng b·ªïng\n",
    "\n",
    "   - crosses_stopped_pct: T·ª∑ l·ªá ch·∫∑n b√≥ng t·∫°t\n",
    "\n",
    "   - def_actions_outside_pen_per90: H√†nh ƒë·ªông ph√≤ng ng·ª± ngo√†i v√≤ng c·∫•m\n",
    "\n",
    "- Ch·ªâ s·ªë ph√°t ƒë·ªông b√≥ng (ƒë·∫∑c th√π GK)\n",
    "\n",
    "   - avg_pass_length: ƒê·ªô d√†i ƒë∆∞·ªùng chuy·ªÅn trung b√¨nh\n",
    "\n",
    "   - launch_pct: T·ª∑ l·ªá ph·∫•t b√≥ng d√†i\n",
    "\n",
    "   - passes_attempted_per90: S·ªë ƒë∆∞·ªùng chuy·ªÅn m·ªói 90 ph√∫t\n",
    "\n",
    "- K·∫øt qu·∫£ tr·∫≠n ƒë·∫•u (ch·ªâ c√≥ √Ω nghƒ©a v·ªõi GK)\n",
    "\n",
    "   - wins_per90: Th·∫Øng m·ªói 90 ph√∫t\n",
    "\n",
    "   - draws_per90: H√≤a m·ªói 90 ph√∫t\n",
    "\n",
    "   - losses_per90: Thua m·ªói 90 ph√∫t\n",
    "\n",
    "C√°c c·ªôt n√†y **CH·ªà** c√≥ gi√° tr·ªã cho th·ªß m√¥n (~10% dataset).\n",
    "\n",
    "V·ªõi 90% d·ªØ li·ªáu l√† **outfield players** ‚Üí missing 90%+.\n",
    "\n",
    "Ng∆∞·ª£c l·∫°i, c√°c ch·ªâ s·ªë outfield (goals, assists, xG...) s·∫Ω = 0 ho·∫∑c kh√¥ng c√≥ √Ω nghƒ©a v·ªõi th·ªß m√¥n.\n",
    "\n",
    "‚Üí **TH·ª¶ M√îN** v√† **OUTFIELD** c√≥ **B·ªò CH·ªà S·ªê HO√ÄN TO√ÄN KH√ÅC NHAU**\n",
    "\n",
    "‚Üí Kh√¥ng th·ªÉ train chung 1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d155c46",
   "metadata": {},
   "source": [
    "Quy·∫øt ƒë·ªãnh lo·∫°i b·ªè c√°c c·ªôt n√†y ra kh·ªèi dataset. V√† lo·∫°i b·ªè v·ªã tr√≠ th·ªß m√¥n ra kh·ªèi m√¥ h√¨nh, tr√°nh ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c ch·ªâ s·ªë c·ªßa c√°c v·ªã tr√≠ kh√°c.\n",
    "\n",
    "L√Ω do:\n",
    "   1. Features GK-specific missing 95%+ v·ªõi outfield players\n",
    "   2. Features outfield (goals, xG, assists) = 0 ho·∫∑c v√¥ nghƒ©a v·ªõi GK\n",
    "   3. Th·ªã tr∆∞·ªùng chuy·ªÉn nh∆∞·ª£ng th·ª±c t·∫ø c≈©ng ƒë·ªãnh gi√° GK v√† outfield \n",
    "      theo ti√™u ch√≠ ho√†n to√†n kh√°c nhau\n",
    "   4. N·∫øu √©p train chung ‚Üí model s·∫Ω h·ªçc sai pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2ed78",
   "metadata": {},
   "source": [
    "**Lo·∫°i b·ªè th·ªß m√¥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78184e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTR∆Ø·ªöC KHI LO·∫†I:\")\n",
    "print(f\"   - T·ªïng samples: {len(df):,}\")\n",
    "print(f\"   - GK: {len(df[df['position_category'] == 'GK']):,}\")\n",
    "print(f\"   - Outfield: {len(df[df['position_category'] != 'GK']):,}\")\n",
    "print(f\"   - Features: {len(df.columns)}\")\n",
    "\n",
    "# Lo·∫°i b·ªè GK\n",
    "df = df[df['position_category'] != 'GK'].copy()\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a v√† drop c√°c c·ªôt GK-specific\n",
    "GK_SPECIFIC_COLS = [\n",
    "    'saves_per90', 'save_percentage', 'clean_sheet_pct', \n",
    "    'goals_against_per90', 'psxg_per_shot', 'psxg_ga_per90',\n",
    "    'penalty_save_pct', 'crosses_stopped_pct', 'shots_on_target_against_per90', \n",
    "    'avg_distance_def_actions', 'def_actions_outside_pen_per90', \n",
    "    'wins_per90', 'draws_per90', 'losses_per90', \n",
    "    'launch_pct', 'avg_pass_length', 'passes_attempted_per90'\n",
    "]\n",
    "\n",
    "gk_cols_dropped = [c for c in GK_SPECIFIC_COLS if c in df.columns]\n",
    "df.drop(columns=gk_cols_dropped, inplace=True)\n",
    "\n",
    "# T·∫°o indicator columns cho outfield\n",
    "position_categories = ['DF', 'MF', 'FW']\n",
    "for pos in position_categories:\n",
    "    df[f'is_{pos}'] = (df['position_category'] == pos).astype(int)\n",
    "\n",
    "print(f\"\\nSAU KHI LO·∫†I:\")\n",
    "print(f\"   - Samples: {len(df):,}\")\n",
    "print(f\"   - Features: {len(df.columns)}\")\n",
    "print(f\"   - ƒê√£ drop: {len(gk_cols_dropped)} c·ªôt GK-specific\")\n",
    "\n",
    "print(f\"\\nPh√¢n b·ªë v·ªã tr√≠ c√≤n l·∫°i:\")\n",
    "for pos, count in df['position_category'].value_counts().items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   {pos}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bfd0e",
   "metadata": {},
   "source": [
    "**Ti·∫øp t·ª•c ki·ªÉm tra Mising Values cho c√°c v·ªã tr√≠ c√≤n l·∫°i**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Pct': (df.isnull().sum().values / len(df) * 100)\n",
    "}).sort_values('Missing_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nC√°c c·ªôt c√≥ missing > 5%:\")\n",
    "print(\"-\" * 80)\n",
    "high_missing = missing_df[missing_df['Missing_Pct'] > 5]\n",
    "for idx, row in high_missing.head(20).iterrows():\n",
    "    status = \"üî¥\" if row['Missing_Pct'] > 50 else \"üü°\" if row['Missing_Pct'] > 20 else \"üü¢\"\n",
    "    print(f\"{status} {row['Column']:45s}: {row['Missing_Pct']:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085aeb4",
   "metadata": {},
   "source": [
    "C√°c c·ªôt c√≥ missing > 50% kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch:\n",
    "   - Impute qu√° nhi·ªÅu gi√° tr·ªã s·∫Ω t·∫°o ra data gi·∫£\n",
    "   - Model s·∫Ω h·ªçc t·ª´ pattern kh√¥ng th·ª±c t·∫ø\n",
    "   - ·∫¢nh h∆∞·ªüng ƒë·∫øn ƒë·ªô tin c·∫≠y c·ªßa k·∫øt qu·∫£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad4151",
   "metadata": {},
   "source": [
    "**Lo·∫°i b·ªè c√°c c·ªôt c√≥ missing > 50%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c23193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo·∫°i b·ªè c√°c c·ªôt c√≥ missing > 50%\n",
      "\n",
      "   H√ÄNH ƒê·ªòNG: Drop 1 c·ªôt\n",
      "--------------------------------------------------------------------------------\n",
      "    foot: 52.6%\n",
      "\n",
      "Dataset sau khi drop: (18544, 58)\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop_missing = missing_df[missing_df['Missing_Pct'] > 50]['Column'].tolist()\n",
    "\n",
    "if cols_to_drop_missing:\n",
    "    print(\"Lo·∫°i b·ªè c√°c c·ªôt c√≥ missing > 50%\")\n",
    "\n",
    "    print(f\"\\n   H√ÄNH ƒê·ªòNG: Drop {len(cols_to_drop_missing)} c·ªôt\")\n",
    "    print(\"-\" * 80)\n",
    "    for col in cols_to_drop_missing:\n",
    "        pct = missing_df[missing_df['Column'] == col]['Missing_Pct'].values[0]\n",
    "        print(f\"    {col}: {pct:.1f}%\")\n",
    "    \n",
    "    df.drop(columns=[c for c in cols_to_drop_missing if c in df.columns], inplace=True)\n",
    "    print(f\"\\nDataset sau khi drop: {df.shape}\")\n",
    "else:\n",
    "    print(\"\\nKh√¥ng c√≥ c·ªôt n√†o missing > 50%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0277b",
   "metadata": {},
   "source": [
    "### **4 X·ª≠ l√≠ Target Missing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03d642a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PH√ÇN T√çCH:\n",
      "   - market_value missing: 3,567 (19.2%)\n",
      "   - market_value c√≥ gi√° tr·ªã: 14,977\n"
     ]
    }
   ],
   "source": [
    "target_missing = df['market_value'].isna().sum()\n",
    "target_missing_pct = target_missing / len(df) * 100\n",
    "\n",
    "print(f\"\\nPH√ÇN T√çCH:\")\n",
    "print(f\"   - market_value missing: {target_missing:,} ({target_missing_pct:.1f}%)\")\n",
    "print(f\"   - market_value c√≥ gi√° tr·ªã: {len(df) - target_missing:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a3045",
   "metadata": {},
   "source": [
    "**market_value** l√† BI·∫æN M·ª§C TI√äU (target variable) c·∫ßn d·ª± ƒëo√°n.\n",
    "\n",
    "KH√îNG ƒê∆Ø·ª¢C PH√âP **IMPUTE target variable** v√¨:\n",
    "   1. Impute = t·∫°o ra gi√° tr·ªã gi·∫£ cho ch√≠nh bi·∫øn c·∫ßn d·ª± ƒëo√°n\n",
    "   2. Model s·∫Ω h·ªçc t·ª´ data kh√¥ng th·ª±c t·∫ø\n",
    "   3. Evaluation metrics s·∫Ω kh√¥ng ph·∫£n √°nh ƒë√∫ng hi·ªáu nƒÉng\n",
    "\n",
    "C√°c d√≤ng kh√¥ng c√≥ market_value = kh√¥ng c√≥ label ‚Üí kh√¥ng d√πng ƒë∆∞·ª£c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f95693c",
   "metadata": {},
   "source": [
    "**Lo·∫°i b·ªè c√°c d√≤ng kh√¥ng c√≥ market_value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ab5f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   H√ÄNH ƒê·ªòNG:\n",
      "   - ƒê√£ lo·∫°i b·ªè: 3,567 d√≤ng\n",
      "   - Dataset c√≤n l·∫°i: 14,977 samples\n"
     ]
    }
   ],
   "source": [
    "if target_missing > 0:\n",
    "    before_count = len(df)\n",
    "    df = df.dropna(subset=['market_value']).copy()\n",
    "    after_count = len(df)\n",
    "    \n",
    "    print(f\"\\n   H√ÄNH ƒê·ªòNG:\")\n",
    "    print(f\"   - ƒê√£ lo·∫°i b·ªè: {before_count - after_count:,} d√≤ng\")\n",
    "    print(f\"   - Dataset c√≤n l·∫°i: {after_count:,} samples\")\n",
    "else:\n",
    "    print(\"\\nKh√¥ng c√≥ d√≤ng n√†o thi·∫øu market_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345f376",
   "metadata": {},
   "source": [
    "#### **5. Ph√¢n t√≠ch Correlation - Ph√°t hi·ªán tr√πng l·∫∑p**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ea3959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C√ÅC C·∫∂P C·ªòT C√ì CORRELATION > 0.95:\n",
      "--------------------------------------------------------------------------------\n",
      "   üî¥ minutes_per_game               <-> calculated_mpg                : 1.0000\n",
      "   üî¥ npxg_per90                     <-> xg_per90                      : 0.9666\n",
      "   üî¥ npxg_xag_per90                 <-> calculated_sum                : 0.9987\n",
      "   üî¥ passes_completed_per90         <-> touches_per90                 : 0.9614\n",
      "   üî¥ carries_per90                  <-> passes_received_per90         : 0.9501\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude_cols = ['market_value', 'is_DF', 'is_MF', 'is_FW']\n",
    "numeric_cols_for_corr = [c for c in numeric_cols if c not in exclude_cols]\n",
    "\n",
    "corr_matrix = df[numeric_cols_for_corr].corr()\n",
    "\n",
    "print(\"\\nC√ÅC C·∫∂P C·ªòT C√ì CORRELATION > 0.95:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.95:\n",
    "            high_corr_pairs.append({\n",
    "                'Column_1': corr_matrix.columns[i],\n",
    "                'Column_2': corr_matrix.columns[j],\n",
    "                'Correlation': corr_val\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    for item in high_corr_pairs:\n",
    "        print(f\"   üî¥ {item['Column_1']:30s} <-> {item['Column_2']:30s}: {item['Correlation']:.4f}\")\n",
    "else:\n",
    "    print(\"    Kh√¥ng c√≥ c·∫∑p n√†o correlation > 0.95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e6b11",
   "metadata": {},
   "source": [
    "C√°c c·ªôt c√≥ correlation > 0.95 ch·ª©a **TH√îNG TIN G·∫¶N NH∆Ø GI·ªêNG NHAU**:\n",
    "   - G√¢y ra **MULTICOLLINEARITY** trong model\n",
    "   - L√†m model kh√≥ x√°c ƒë·ªãnh feature n√†o th·ª±c s·ª± quan tr·ªçng\n",
    "   - TƒÉng variance c·ªßa coefficients\n",
    "   - C√≥ th·ªÉ g√¢y overfitting\n",
    "\n",
    "Gi·∫£i ph√°p: Gi·ªØ l·∫°i c·ªôt c√≥ correlation **CAO H∆†N** v·ªõi target (market_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "015e9735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Drop 'minutes_per_game' (corr v·ªõi target: 0.1215)\n",
      "      Gi·ªØ 'calculated_mpg' (corr v·ªõi target: 0.1319)\n",
      "      Drop 'npxg_per90' (corr v·ªõi target: 0.1464)\n",
      "      Gi·ªØ 'xg_per90' (corr v·ªõi target: 0.1504)\n",
      "      Drop 'npxg_xag_per90' (corr v·ªõi target: 0.1865)\n",
      "      Gi·ªØ 'calculated_sum' (corr v·ªõi target: 0.2726)\n",
      "      Drop 'touches_per90' (corr v·ªõi target: 0.1110)\n",
      "      Gi·ªØ 'passes_completed_per90' (corr v·ªõi target: 0.1292)\n",
      "      Drop 'carries_per90' (corr v·ªõi target: 0.1691)\n",
      "      Gi·ªØ 'passes_received_per90' (corr v·ªõi target: 0.1933)\n",
      "\n",
      "ƒê√£ drop 5 c·ªôt duplicate\n",
      "   Dataset: (14977, 53)\n"
     ]
    }
   ],
   "source": [
    "if high_corr_pairs:\n",
    "    # T√≠nh correlation v·ªõi target ƒë·ªÉ quy·∫øt ƒë·ªãnh gi·ªØ c·ªôt n√†o\n",
    "    target_corr = {}\n",
    "    for col in numeric_cols_for_corr:\n",
    "        valid_data = df[[col, 'market_value']].dropna()\n",
    "        if len(valid_data) > 30:\n",
    "            target_corr[col] = valid_data[col].corr(valid_data['market_value'])\n",
    "\n",
    "\n",
    "    cols_to_drop_duplicate = []\n",
    "   \n",
    "    for item in high_corr_pairs:\n",
    "        col1, col2 = item['Column_1'], item['Column_2']\n",
    "        corr1 = abs(target_corr.get(col1, 0))\n",
    "        corr2 = abs(target_corr.get(col2, 0))\n",
    "        \n",
    "        to_drop = col1 if corr1 < corr2 else col2\n",
    "        to_keep = col2 if corr1 < corr2 else col1\n",
    "        \n",
    "        if to_drop not in cols_to_drop_duplicate:\n",
    "            cols_to_drop_duplicate.append(to_drop)\n",
    "            print(f\"      Drop '{to_drop}' (corr v·ªõi target: {abs(target_corr.get(to_drop, 0)):.4f})\")\n",
    "            print(f\"      Gi·ªØ '{to_keep}' (corr v·ªõi target: {abs(target_corr.get(to_keep, 0)):.4f})\")\n",
    "    \n",
    "    df.drop(columns=[c for c in cols_to_drop_duplicate if c in df.columns], inplace=True)\n",
    "    print(f\"\\nƒê√£ drop {len(cols_to_drop_duplicate)} c·ªôt duplicate\")\n",
    "    print(f\"   Dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba923c",
   "metadata": {},
   "source": [
    "#### **5. Ph√¢n t√≠ch Correlation v·ªõi Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cee183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà TOP 15 FEATURES T∆Ø∆†NG QUAN CAO NH·∫§T V·ªöI MARKET_VALUE:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. Weak   üìà calculated_sum                          :  0.2726\n",
      " 2. Weak   üìà goals                                   :  0.2579\n",
      " 3. Weak   üìà assists                                 :  0.2420\n",
      " 4. Weak   üìà minutes_played                          :  0.2026\n",
      " 5. Weak   üìà appearances                             :  0.1955\n",
      " 6. Weak   üìà passes_received_per90                   :  0.1933\n",
      " 7. Weak   üìà touches_att_pen_per90                   :  0.1878\n",
      " 8. Weak   üìà gca_per90                               :  0.1777\n",
      " 9. Weak   üìà touches_att_third_per90                 :  0.1768\n",
      "10. Weak   üìà npg_per90                               :  0.1636\n",
      "11. Weak   üìà xag_per90                               :  0.1623\n",
      "12. Weak   üìà progressive_carries_per90               :  0.1621\n",
      "13. Weak   üìà sca_per90                               :  0.1606\n",
      "14. Weak   üìà xg_per90                                :  0.1504\n",
      "15. Weak   üìà shots_on_target_per90                   :  0.1502\n",
      "\n",
      "üìâ C√ÅC C·ªòT C√ì CORRELATION < 0.03 (g·∫ßn nh∆∞ kh√¥ng li√™n quan):\n",
      "--------------------------------------------------------------------------------\n",
      "   üü¢ height                                  :  0.0285\n",
      "   üü¢ assists_per_90                          :  0.0077\n",
      "   üü¢ take_on_success_pct                     : -0.0283\n",
      "   üü¢ tackles_per90                           : -0.0251\n",
      "   üü¢ aerial_win_pct                          : -0.0072\n",
      "   üü¢ red_cards_per90                         : -0.0268\n"
     ]
    }
   ],
   "source": [
    "# C·∫≠p nh·∫≠t l·∫°i danh s√°ch c·ªôt sau khi drop\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols_for_corr = [c for c in numeric_cols if c not in exclude_cols]\n",
    "\n",
    "target_corr = {}\n",
    "for col in numeric_cols_for_corr:\n",
    "    valid_data = df[[col, 'market_value']].dropna()\n",
    "    if len(valid_data) > 30:\n",
    "        target_corr[col] = valid_data[col].corr(valid_data['market_value'])\n",
    "\n",
    "target_corr_sorted = sorted(target_corr.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"\\nüìà TOP 15 FEATURES T∆Ø∆†NG QUAN CAO NH·∫§T V·ªöI MARKET_VALUE:\")\n",
    "print(\"-\" * 80)\n",
    "for i, (col, corr) in enumerate(target_corr_sorted[:15], 1):\n",
    "    emoji = \"üìà\" if corr > 0 else \"üìâ\"\n",
    "    strength = \"Strong\" if abs(corr) > 0.5 else \"Medium\" if abs(corr) > 0.3 else \"Weak\"\n",
    "    print(f\"{i:2d}. {strength:6s} {emoji} {col:40s}: {corr:7.4f}\")\n",
    "\n",
    "# T√¨m c·ªôt c√≥ correlation th·∫•p\n",
    "low_corr_cols = [col for col, corr in target_corr.items() if abs(corr) < 0.03]\n",
    "\n",
    "print(f\"\\nüìâ C√ÅC C·ªòT C√ì CORRELATION < 0.03 (g·∫ßn nh∆∞ kh√¥ng li√™n quan):\")\n",
    "print(\"-\" * 80)\n",
    "for col in low_corr_cols:\n",
    "    print(f\"   üü¢ {col:40s}: {target_corr[col]:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9ac68",
   "metadata": {},
   "source": [
    "C√°c c·ªôt c√≥ |correlation| < 0.03 v·ªõi market_value:\n",
    "   - G·∫ßn nh∆∞ KH√îNG C√ì M·ªêI QUAN H·ªÜ TUY·∫æN T√çNH v·ªõi target\n",
    "   - Kh√¥ng ƒë√≥ng g√≥p nhi·ªÅu v√†o vi·ªác d·ª± ƒëo√°n\n",
    "   - C√≥ th·ªÉ g√¢y nhi·ªÖu (noise) cho model\n",
    "   - TƒÉng dimensionality kh√¥ng c·∫ßn thi·∫øt\n",
    "\n",
    "L∆∞u √Ω: M·ªôt s·ªë c·ªôt c√≥ th·ªÉ c√≥ quan h·ªá PHI TUY·∫æN v·ªõi target\n",
    "‚Üí C√¢n nh·∫Øc gi·ªØ l·∫°i n·∫øu c√≥ l√Ω do domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   H√ÄNH ƒê·ªòNG: Drop 6 c·ªôt\n",
      "--------------------------------------------------------------------------------\n",
      "    height: correlation = 0.0285\n",
      "    assists_per_90: correlation = 0.0077\n",
      "    take_on_success_pct: correlation = -0.0283\n",
      "    tackles_per90: correlation = -0.0251\n",
      "    aerial_win_pct: correlation = -0.0072\n",
      "    red_cards_per90: correlation = -0.0268\n",
      "\n",
      "Dataset sau khi drop: (14977, 47)\n"
     ]
    }
   ],
   "source": [
    "if low_corr_cols:\n",
    "    print(f\"\\n   H√ÄNH ƒê·ªòNG: Drop {len(low_corr_cols)} c·ªôt\")\n",
    "    print(\"-\" * 80)\n",
    "    for col in low_corr_cols:\n",
    "        print(f\"    {col}: correlation = {target_corr[col]:.4f}\")\n",
    "    \n",
    "    df.drop(columns=[c for c in low_corr_cols if c in df.columns], inplace=True)\n",
    "    print(f\"\\nDataset sau khi drop: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9dc87",
   "metadata": {},
   "source": [
    "### **7. C·ªôt t√≠nh to√°n t·ª´ c·ªôt kh√°c**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ce20cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_candidates = []\n",
    "\n",
    "# Check minutes_per_game = minutes_played / appearances\n",
    "if all(col in df.columns for col in ['minutes_per_game', 'minutes_played', 'appearances']):\n",
    "    calculated = df['minutes_played'] / df['appearances'].replace(0, 1)\n",
    "    valid = pd.DataFrame({\n",
    "        'original': df['minutes_per_game'],\n",
    "        'calculated': calculated\n",
    "    }).dropna()\n",
    "    \n",
    "    if len(valid) > 10:\n",
    "        corr = valid['original'].corr(valid['calculated'])\n",
    "        if abs(corr) > 0.99:\n",
    "            derived_candidates.append({\n",
    "                'column': 'minutes_per_game',\n",
    "                'formula': 'minutes_played / appearances',\n",
    "                'correlation': corr\n",
    "            })\n",
    "\n",
    "# Check npxg_xag_per90 = npxg_per90 + xag_per90\n",
    "if all(col in df.columns for col in ['npxg_xag_per90', 'npxg_per90', 'xag_per90']):\n",
    "    calculated = df['npxg_per90'] + df['xag_per90']\n",
    "    valid = pd.DataFrame({\n",
    "        'original': df['npxg_xag_per90'],\n",
    "        'calculated': calculated\n",
    "    }).dropna()\n",
    "    \n",
    "    if len(valid) > 10:\n",
    "        corr = valid['original'].corr(valid['calculated'])\n",
    "        if abs(corr) > 0.95:\n",
    "            derived_candidates.append({\n",
    "                'column': 'npxg_xag_per90',\n",
    "                'formula': 'npxg_per90 + xag_per90',\n",
    "                'correlation': corr\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b532cc",
   "metadata": {},
   "source": [
    "C√°c c·ªôt derived (t√≠nh to√°n t·ª´ c·ªôt kh√°c) ch·ª©a TH√îNG TIN TR√ôNG L·∫∂P:\n",
    "   - minutes_per_game = minutes_played / appearances\n",
    "   - npxg_xag_per90 = npxg_per90 + xag_per90\n",
    "\n",
    "V·∫•n ƒë·ªÅ:\n",
    "   - Th√¥ng tin ƒë√£ c√≥ trong c√°c c·ªôt g·ªëc\n",
    "   - G√¢y ra multicollinearity\n",
    "   - Kh√¥ng th√™m gi√° tr·ªã d·ª± ƒëo√°n m·ªõi\n",
    "\n",
    "Gi·ªØ l·∫°i c√°c c·ªôt g·ªëc v√¨ ch√∫ng mang √Ω nghƒ©a r√µ r√†ng h∆°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88acdeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kh√¥ng ph√°t hi·ªán c·ªôt derived r√µ r√†ng\n"
     ]
    }
   ],
   "source": [
    "if derived_candidates:\n",
    "    print(\"\\nC√ÅC C·ªòT DERIVED ƒê∆Ø·ª¢C PH√ÅT HI·ªÜN:\")\n",
    "    print(\"-\" * 80)\n",
    "    for item in derived_candidates:\n",
    "        print(f\"   ‚úì {item['column']} = {item['formula']} (corr: {item['correlation']:.4f})\")\n",
    "\n",
    "   \n",
    "    cols_to_drop_derived = [item['column'] for item in derived_candidates]\n",
    "    print(f\"\\n   H√ÄNH ƒê·ªòNG: Drop {len(cols_to_drop_derived)} c·ªôt\")\n",
    "    print(\"-\" * 80)\n",
    "    for item in derived_candidates:\n",
    "        print(f\"    {item['column']} (= {item['formula']})\")\n",
    "    \n",
    "    df.drop(columns=[c for c in cols_to_drop_derived if c in df.columns], inplace=True)\n",
    "    print(f\"\\nDataset sau khi drop: {df.shape}\")\n",
    "else:\n",
    "    print(\"\\nKh√¥ng ph√°t hi·ªán c·ªôt derived r√µ r√†ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12faadc",
   "metadata": {},
   "source": [
    "### **8. Metadata Column - C√°c c·ªôt kh√¥ng c·∫ßn cho model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76021e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C√ÅC C·ªòT METADATA TRONG DATASET:\n",
      "--------------------------------------------------------------------------------\n",
      "   - player_id\n",
      "   - player_name\n",
      "   - position\n",
      "   - position_category\n",
      "\n",
      "   H√ÄNH ƒê·ªòNG: Drop 4 c·ªôt\n",
      "--------------------------------------------------------------------------------\n",
      "    player_id\n",
      "    player_name\n",
      "    position\n",
      "    position_category\n",
      "\n",
      "Dataset sau khi drop: (14977, 43)\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = ['player_id', 'player_name', 'foot', 'position', 'position_category']\n",
    "metadata_in_df = [c for c in metadata_cols if c in df.columns]\n",
    "\n",
    "print(\"\\nC√ÅC C·ªòT METADATA TRONG DATASET:\")\n",
    "print(\"-\" * 80)\n",
    "for col in metadata_in_df:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "\n",
    "print(f\"\\n   H√ÄNH ƒê·ªòNG: Drop {len(metadata_in_df)} c·ªôt\")\n",
    "print(\"-\" * 80)\n",
    "for col in metadata_in_df:\n",
    "    print(f\"    {col}\")\n",
    "\n",
    "df.drop(columns=[c for c in metadata_in_df if c in df.columns], inplace=True)\n",
    "print(f\"\\nDataset sau khi drop: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb8221",
   "metadata": {},
   "source": [
    "C√°c c·ªôt metadata KH√îNG N√äN d√πng cho modeling:\n",
    "\n",
    "   - player_id: M√£ ƒë·ªãnh danh, kh√¥ng c√≥ √Ω nghƒ©a d·ª± ƒëo√°n\n",
    "   - player_name: T√™n c·∫ßu th·ªß, kh√¥ng n√™n d√πng (data leakage)\n",
    "   - foot: Ch√¢n thu·∫≠n - √≠t ·∫£nh h∆∞·ªüng ƒë·∫øn gi√° tr·ªã\n",
    "   - position: ƒê√£ ƒë∆∞·ª£c encode th√†nh is_DF, is_MF, is_FW\n",
    "   - position_category: T∆∞∆°ng t·ª±, ƒë√£ encode\n",
    "\n",
    "L∆∞u √Ω: nationality, current_club, league s·∫Ω ƒë∆∞·ª£c gi·ªØ l·∫°i\n",
    "v√† encode ri√™ng trong b∆∞·ªõc modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00956343",
   "metadata": {},
   "source": [
    "### **9. Ph√¢n t√≠ch VIF (Multicollinearity)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731de457",
   "metadata": {},
   "source": [
    "VIF > 100 cho th·∫•y MULTICOLLINEARITY C·ª∞C CAO:\n",
    "   - C√°c c·ªôt n√†y c√≥ th·ªÉ ƒë∆∞·ª£c d·ª± ƒëo√°n g·∫ßn nh∆∞ ho√†n h·∫£o t·ª´ c·ªôt kh√°c\n",
    "   - G√¢y ra instability trong model coefficients\n",
    "   - C√≥ th·ªÉ d·∫´n ƒë·∫øn overfitting\n",
    "\n",
    "Tuy nhi√™n, v·ªõi tree-based models (RF, XGBoost, LightGBM):\n",
    "   - Multicollinearity √çT ·∫¢NH H∆Ø·ªûNG h∆°n so v·ªõi linear models\n",
    "   - C√≥ th·ªÉ gi·ªØ l·∫°i v√† ƒë·ªÉ model t·ª± ch·ªçn features quan tr·ªçng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7e207b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T√≠nh VIF tr√™n 11,601 samples v·ªõi 8 features\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "TOP 10 VIF CAO NH·∫§T:\n",
      "üü°   minutes_played                          :      36.56\n",
      "üü°   appearances                             :      32.52\n",
      "üü°   calculated_mpg                          :      21.22\n",
      "üü°   age                                     :      15.75\n",
      "‚úÖ   goals                                   :       2.87\n",
      "‚úÖ   calculated_sum                          :       2.50\n",
      "‚úÖ   assists                                 :       2.34\n",
      "‚úÖ   goals_per_90                            :       1.89\n",
      "\n",
      "‚úÖ Kh√¥ng c√≥ c·ªôt n√†o c√≥ VIF c·ª±c cao (>100)\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude_cols = ['market_value', 'is_DF', 'is_MF', 'is_FW']\n",
    "cols_for_vif = [c for c in numeric_cols if c not in exclude_cols]\n",
    "cols_for_vif = [c for c in cols_for_vif if df[c].isnull().sum() / len(df) < 0.3][:25]\n",
    "\n",
    "df_vif = df[cols_for_vif].dropna()\n",
    "\n",
    "if len(df_vif) > 100 and len(cols_for_vif) > 1:\n",
    "    print(f\"\\nT√≠nh VIF tr√™n {len(df_vif):,} samples v·ªõi {len(cols_for_vif)} features\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    try:\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"Feature\"] = cols_for_vif\n",
    "        vif_data[\"VIF\"] = [variance_inflation_factor(df_vif.values, i) \n",
    "                          for i in range(len(cols_for_vif))]\n",
    "        vif_data = vif_data.sort_values('VIF', ascending=False)\n",
    "        \n",
    "        print(\"\\nTOP 10 VIF CAO NH·∫§T:\")\n",
    "        for idx, row in vif_data.head(10).iterrows():\n",
    "            if row['VIF'] > 100:\n",
    "                status = \"üî¥üî¥\"\n",
    "            elif row['VIF'] > 50:\n",
    "                status = \"üî¥  \"\n",
    "            elif row['VIF'] > 10:\n",
    "                status = \"üü°  \"\n",
    "            else:\n",
    "                status = \"‚úÖ  \"\n",
    "            print(f\"{status} {row['Feature']:40s}: {row['VIF']:10.2f}\")\n",
    "        \n",
    "        # Ki·ªÉm tra c√≥ c·ªôt VIF > 100 kh√¥ng\n",
    "        very_high_vif = vif_data[vif_data['VIF'] > 100]['Feature'].tolist()\n",
    "        \n",
    "        if very_high_vif:         \n",
    "            print(\"=\"*80)\n",
    "            print(\"QUY·∫æT ƒê·ªäNH: Gi·ªØ nguy√™n (tree-based models robust v·ªõi multicollinearity)\")\n",
    "            print(\"=\"*80)\n",
    "        else:\n",
    "            print(\"\\n‚úÖ Kh√¥ng c√≥ c·ªôt n√†o c√≥ VIF c·ª±c cao (>100)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Kh√¥ng th·ªÉ t√≠nh VIF: {str(e)}\")\n",
    "else:\n",
    "    print(\"WARNING: Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh VIF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404f837",
   "metadata": {},
   "source": [
    "### **10. Imputation - X·ª≠ l√≠ Missing c√≤n l·∫°i**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b334e",
   "metadata": {},
   "source": [
    "Sau khi lo·∫°i b·ªè c√°c c·ªôt c√≥ missing cao, c√≤n l·∫°i m·ªôt s·ªë missing nh·ªè:\n",
    "   - C√≥ th·ªÉ do d·ªØ li·ªáu kh√¥ng ƒë∆∞·ª£c thu th·∫≠p ƒë·∫ßy ƒë·ªß\n",
    "   - M·ªôt s·ªë c·∫ßu th·ªß thi·∫øu th√¥ng tin ·ªü m·ªôt v√†i ch·ªâ s·ªë\n",
    "\n",
    "Ph∆∞∆°ng ph√°p x·ª≠ l√Ω:\n",
    "   - Numeric columns: Impute b·∫±ng MEDIAN\n",
    "     ‚Üí Median robust v·ªõi outliers (d·ªØ li·ªáu b√≥ng ƒë√° th∆∞·ªùng c√≥ outliers)\n",
    "   - Categorical columns: Impute b·∫±ng MODE (gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bfc2c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PH√ÇN T√çCH MISSING C√íN L·∫†I:\n",
      "   - Total missing: 157,991 cells (24.53%)\n",
      "\n",
      "   C√°c c·ªôt c√≤n missing:\n",
      "   - shots_on_target_pct: 5808 (38.8%) - float64\n",
      "   - avg_shot_distance: 5808 (38.8%) - float64\n",
      "   - passes_into_final_third_per90: 5482 (36.6%) - float64\n",
      "   - progressive_passes_per90: 5482 (36.6%) - float64\n",
      "   - yellow_cards_per90: 5482 (36.6%) - float64\n",
      "   - aerials_won_per90: 5482 (36.6%) - float64\n",
      "   - ball_recoveries_per90: 5482 (36.6%) - float64\n",
      "   - blocks_per90: 5482 (36.6%) - float64\n",
      "   - interceptions_per90: 5482 (36.6%) - float64\n",
      "   - passes_received_per90: 5482 (36.6%) - float64\n",
      "   - touches_att_pen_per90: 5482 (36.6%) - float64\n",
      "   - touches_att_third_per90: 5482 (36.6%) - float64\n",
      "   - carries_into_final_third_per90: 5482 (36.6%) - float64\n",
      "   - take_ons_per90: 5482 (36.6%) - float64\n",
      "   - progressive_carries_per90: 5482 (36.6%) - float64\n",
      "   - progressive_passes_rec_per90: 5482 (36.6%) - float64\n",
      "   - fouls_committed_per90: 5482 (36.6%) - float64\n",
      "   - passes_into_penalty_area_per90: 5482 (36.6%) - float64\n",
      "   - pass_completion_pct: 5482 (36.6%) - float64\n",
      "   - passes_completed_per90: 5482 (36.6%) - float64\n",
      "   - key_passes_per90: 5482 (36.6%) - float64\n",
      "   - gca_per90: 5482 (36.6%) - float64\n",
      "   - sca_per90: 5482 (36.6%) - float64\n",
      "   - shots_on_target_per90: 5482 (36.6%) - float64\n",
      "   - shots_per90: 5482 (36.6%) - float64\n",
      "   - xg_per90: 5482 (36.6%) - float64\n",
      "   - xag_per90: 5482 (36.6%) - float64\n",
      "   - npg_per90: 5482 (36.6%) - float64\n",
      "   - goals_per_90: 3292 (22.0%) - float64\n",
      "   - age: 342 (2.3%) - float64\n",
      "   - nationality: 209 (1.4%) - object\n",
      "   - Numeric: Imputed 157782 values b·∫±ng median\n",
      "   - nationality: Imputed 209 values b·∫±ng mode ('Argentina')\n",
      "\n",
      "Missing sau impute: 0\n"
     ]
    }
   ],
   "source": [
    "total_missing = df.isnull().sum().sum()\n",
    "total_cells = len(df) * len(df.columns)\n",
    "missing_pct = total_missing / total_cells * 100\n",
    "\n",
    "print(f\"\\nPH√ÇN T√çCH MISSING C√íN L·∫†I:\")\n",
    "print(f\"   - Total missing: {total_missing:,} cells ({missing_pct:.2f}%)\")\n",
    "\n",
    "# Chi ti·∫øt t·ª´ng c·ªôt\n",
    "missing_by_col = df.isnull().sum()\n",
    "cols_with_missing = missing_by_col[missing_by_col > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(cols_with_missing) > 0:\n",
    "    print(f\"\\n   C√°c c·ªôt c√≤n missing:\")\n",
    "    for col, count in cols_with_missing.items():\n",
    "        pct = count / len(df) * 100\n",
    "        dtype = df[col].dtype\n",
    "        print(f\"   - {col}: {count} ({pct:.1f}%) - {dtype}\")\n",
    "\n",
    "\n",
    "# Impute numeric\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cols_to_impute = [c for c in numeric_cols if c != 'market_value']\n",
    "\n",
    "before_missing = df[cols_to_impute].isnull().sum().sum()\n",
    "\n",
    "if before_missing > 0:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df[cols_to_impute] = imputer.fit_transform(df[cols_to_impute])\n",
    "    print(f\"   - Numeric: Imputed {before_missing} values b·∫±ng median\")\n",
    "\n",
    "# Impute categorical\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in cat_cols:\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        mode_val = df[col].mode()[0] if len(df[col].mode()) > 0 else 'Unknown'\n",
    "        df[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"   - {col}: Imputed {missing_count} values b·∫±ng mode ('{mode_val}')\")\n",
    "\n",
    "after_missing = df.isnull().sum().sum()\n",
    "print(f\"\\nMissing sau impute: {after_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ddd0b",
   "metadata": {},
   "source": [
    "### **11. Ki·ªÉm tra d·ªØ li·ªáu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5d661bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET CU·ªêI C√ôNG:\n",
      "   - Samples: 14,977\n",
      "   - Features: 43\n",
      "   - Missing: 0\n",
      "\n",
      "TARGET (market_value):\n",
      "   - Min: 0.01\n",
      "   - Max: 200.00\n",
      "   - Mean: 3.45\n",
      "   - Median: 0.60\n",
      "\n",
      "FEATURES:\n",
      "   - Numeric: 40 c·ªôt\n",
      "   - Categorical: 3 c·ªôt ‚Üí ['nationality', 'current_club', 'league']\n",
      "\n",
      "DANH S√ÅCH C·ªòT:\n",
      "['age', 'nationality', 'current_club', 'league', 'appearances', 'minutes_played', 'goals', 'assists', 'goals_per_90', 'npg_per90', 'xag_per90', 'xg_per90', 'shots_per90', 'shots_on_target_per90', 'shots_on_target_pct', 'avg_shot_distance', 'sca_per90', 'gca_per90', 'key_passes_per90', 'passes_completed_per90', 'pass_completion_pct', 'passes_into_final_third_per90', 'passes_into_penalty_area_per90', 'progressive_passes_per90', 'progressive_passes_rec_per90', 'progressive_carries_per90', 'take_ons_per90', 'carries_into_final_third_per90', 'touches_att_third_per90', 'touches_att_pen_per90', 'passes_received_per90', 'interceptions_per90', 'blocks_per90', 'ball_recoveries_per90', 'aerials_won_per90', 'yellow_cards_per90', 'fouls_committed_per90', 'market_value', 'is_DF', 'is_MF', 'is_FW', 'calculated_mpg', 'calculated_sum']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nDATASET CU·ªêI C√ôNG:\")\n",
    "print(f\"   - Samples: {len(df):,}\")\n",
    "print(f\"   - Features: {len(df.columns)}\")\n",
    "print(f\"   - Missing: {df.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nTARGET (market_value):\")\n",
    "print(f\"   - Min: {df['market_value'].min():,.2f}\")\n",
    "print(f\"   - Max: {df['market_value'].max():,.2f}\")\n",
    "print(f\"   - Mean: {df['market_value'].mean():,.2f}\")\n",
    "print(f\"   - Median: {df['market_value'].median():,.2f}\")\n",
    "\n",
    "print(f\"\\nFEATURES:\")\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"   - Numeric: {len(numeric_features)} c·ªôt\")\n",
    "print(f\"   - Categorical: {len(cat_features)} c·ªôt ‚Üí {cat_features}\")\n",
    "\n",
    "print(f\"\\nDANH S√ÅCH C·ªòT:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8a10e",
   "metadata": {},
   "source": [
    "### **12. Export d·ªØ li·ªáu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee67f2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to: output\\football_players_dataset.csv\n",
      "   - Rows: 14,977\n",
      "   - Columns: 43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# S·∫Øp x·∫øp c·ªôt\n",
    "column_order = ['age', 'nationality', 'current_club', 'league', \n",
    "                'appearances', 'minutes_played', 'is_DF', 'is_MF', 'is_FW']\n",
    "\n",
    "other_cols = [c for c in df.columns \n",
    "              if c not in column_order and c != 'market_value']\n",
    "column_order.extend(other_cols)\n",
    "column_order.append('market_value')\n",
    "column_order = [c for c in column_order if c in df.columns]\n",
    "\n",
    "df_final = df[column_order]\n",
    "\n",
    "# T·∫°o folder v√† l∆∞u\n",
    "output_folder = os.path.dirname(FINAL_OUTPUT_FILE)\n",
    "if output_folder:\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "df_final.to_csv(FINAL_OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"\\nSaved to: {FINAL_OUTPUT_FILE}\")\n",
    "print(f\"   - Rows: {len(df_final):,}\")\n",
    "print(f\"   - Columns: {len(df_final.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
