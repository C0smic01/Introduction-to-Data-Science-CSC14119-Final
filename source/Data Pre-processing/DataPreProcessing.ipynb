{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc65abe2",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bca97f",
   "metadata": {},
   "source": [
    "### **I. Import thÆ° viá»‡n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e54ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3eb3d6",
   "metadata": {},
   "source": [
    "### **II. Ná»‘i cÃ¡c file csv thu tháº­p Ä‘Æ°á»£c thÃ nh má»™t file duy nháº¥t**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc46af",
   "metadata": {},
   "source": [
    "Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n folder chá»©a cÃ¡c file csv input vÃ  tÃªn file csv output sau khi ná»‘i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c69bc041",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"data\"  \n",
    "OUTPUT_FOLDER = \"output\"\n",
    "RAW_FILENAME = \"football_players_raw_dataset.csv\"\n",
    "FINAL_FILENAME = \"football_players_dataset.csv\"\n",
    "\n",
    "RAW_OUTPUT_FILE = os.path.join(OUTPUT_FOLDER, \"football_players_raw_dataset.csv\")\n",
    "FINAL_OUTPUT_FILE = os.path.join(OUTPUT_FOLDER, \"football_players_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0165c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv(folder_path, output_folder, output_filename, drop_duplicate=True):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    if not all_files:\n",
    "        print(\"Not found any CSV files in the folder.\")\n",
    "        return\n",
    "    \n",
    "    dfs = []\n",
    "\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            print(f\"Loaded: {file} ({len(df)} rows)\")\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Read error for file {file}: {e}\")\n",
    "\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    if drop_duplicate:\n",
    "        before = len(merged_df)\n",
    "        merged_df = merged_df.drop_duplicates(subset=\"player_id\", keep=\"last\")\n",
    "        after = len(merged_df)\n",
    "        print(f\"Removed {before - after} duplicates\")\n",
    "\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Merged file saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d79cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data\\A-League_Men.csv (378 rows)\n",
      "Loaded: data\\Allsvenskan.csv (523 rows)\n",
      "Loaded: data\\Argentine_Liga.csv (1274 rows)\n",
      "Loaded: data\\Austrian_Bundesliga.csv (390 rows)\n",
      "Loaded: data\\Belgian_Pro_League.csv (578 rows)\n",
      "Loaded: data\\Bolivian_Primera_DivisiÃ³n.csv (115 rows)\n",
      "Loaded: data\\Bundesliga.csv (578 rows)\n",
      "Loaded: data\\Canadian_Premier_League.csv (13 rows)\n",
      "Loaded: data\\Challenger_Pro_League.csv (515 rows)\n",
      "Loaded: data\\Chilean_Primera_DivisiÃ³n.csv (198 rows)\n",
      "Loaded: data\\Chinese_Super_League.csv (525 rows)\n",
      "Loaded: data\\Croatian_Football_League.csv (108 rows)\n",
      "Loaded: data\\Czech_First_League.csv (619 rows)\n",
      "Loaded: data\\Danish_Superliga.csv (159 rows)\n",
      "Loaded: data\\Eerste_Divisie.csv (25 rows)\n",
      "Loaded: data\\EFL_League_One.csv (270 rows)\n",
      "Loaded: data\\EFL_League_Two.csv (105 rows)\n",
      "Loaded: data\\Ekstraklasa.csv (2 rows)\n",
      "Loaded: data\\Eliteserien.csv (523 rows)\n",
      "Loaded: data\\Eredivisie.csv (638 rows)\n",
      "Loaded: data\\football_players_full_dataset.csv (20682 rows)\n",
      "Loaded: data\\Hrvatska_NL.csv (415 rows)\n",
      "Loaded: data\\Indian_Super_League.csv (15 rows)\n",
      "Loaded: data\\J1_League.csv (691 rows)\n",
      "Loaded: data\\J2_League.csv (647 rows)\n",
      "Loaded: data\\K_League_1.csv (25 rows)\n",
      "Loaded: data\\La_Liga.csv (749 rows)\n",
      "Loaded: data\\League_of_Ireland_Premier_Division.csv (54 rows)\n",
      "Loaded: data\\Liga_1.csv (593 rows)\n",
      "Loaded: data\\Liga_I.csv (136 rows)\n",
      "Loaded: data\\Liga_MX.csv (714 rows)\n",
      "Loaded: data\\Liga_Profesional_Ecuador.csv (154 rows)\n",
      "Loaded: data\\Ligue_1.csv (666 rows)\n",
      "Loaded: data\\Ligue_2.csv (172 rows)\n",
      "Loaded: data\\MLS.csv (506 rows)\n",
      "Loaded: data\\National_League.csv (38 rows)\n",
      "Loaded: data\\NB_I.csv (81 rows)\n",
      "Loaded: data\\Paraguayan_Primera_DivisiÃ³n.csv (21 rows)\n",
      "Loaded: data\\Persian_Gulf_Pro_League.csv (29 rows)\n",
      "Loaded: data\\Premier_League.csv (702 rows)\n",
      "Loaded: data\\Primeira_Liga.csv (652 rows)\n",
      "Loaded: data\\Primera_A.csv (234 rows)\n",
      "Loaded: data\\Russian_Premier_League.csv (573 rows)\n",
      "Loaded: data\\Saudio_Pro_League.csv (608 rows)\n",
      "Loaded: data\\Scottish_Premiership.csv (399 rows)\n",
      "Loaded: data\\Segunda_DivisiÃ³n.csv (259 rows)\n",
      "Loaded: data\\Serbian_SuperLiga.csv (645 rows)\n",
      "Loaded: data\\Serie_A.csv (811 rows)\n",
      "Loaded: data\\South_African_Premiership.csv (532 rows)\n",
      "Loaded: data\\Superettan.csv (456 rows)\n",
      "Loaded: data\\Super_League_Greece.csv (224 rows)\n",
      "Loaded: data\\Swiss_Super_League.csv (437 rows)\n",
      "Loaded: data\\SÃ©rie_A.csv (652 rows)\n",
      "Loaded: data\\SÃ©rie_B.csv (332 rows)\n",
      "Loaded: data\\SÃ¼per_Lig.csv (726 rows)\n",
      "Loaded: data\\Ukrainian-Premier-League.csv (32 rows)\n",
      "Loaded: data\\Uruguayan_Primera_DivisiÃ³n.csv (0 rows)\n",
      "Loaded: data\\Veikkausliiga.csv (374 rows)\n",
      "Loaded: data\\Venezuelan_Primera_Division.csv (117 rows)\n",
      "Removed 22007 duplicates\n",
      "Merged file saved at: output\\football_players_raw_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "merge_csv(INPUT_FOLDER, OUTPUT_FOLDER, RAW_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826171b2",
   "metadata": {},
   "source": [
    "### **III. Tiá»n xá»­ lÃ­ dá»¯ liá»‡u**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92cf1c",
   "metadata": {},
   "source": [
    "#### **1. Äá»c vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50b98d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Táº­p dá»¯ liá»‡u: 20682 players, 70 features\n",
      "\n",
      "ThÃ´ng tin cÆ¡ báº£n:\n",
      "   - GiÃ¡ trá»‹ thiáº¿u (Missing values): 764,870 cells\n",
      "   - Bá»™ nhá»› sá»­ dá»¥ng (Memory usage): 19.17 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(RAW_OUTPUT_FILE)\n",
    "print(f\"\\nTáº­p dá»¯ liá»‡u: {df.shape[0]} players, {df.shape[1]} features\")\n",
    "\n",
    "\n",
    "print(\"\\nThÃ´ng tin cÆ¡ báº£n:\")\n",
    "print(f\"   - GiÃ¡ trá»‹ thiáº¿u (Missing values): {df.isnull().sum().sum():,} cells\")\n",
    "print(f\"   - Bá»™ nhá»› sá»­ dá»¥ng (Memory usage): {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a40a0",
   "metadata": {},
   "source": [
    "#### **2. PhÃ¢n loáº¡i vá»‹ trÃ­ cáº§u thá»§**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "485119b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHÃ‚N LOáº I Vá»Š TRÃ Cáº¦U THá»¦\n",
      "\n",
      "- PhÃ¢n bá»‘ vá»‹ trÃ­:\n",
      "   MF      : 8136 cáº§u thá»§ ( 39.3%)\n",
      "   DF      : 7192 cáº§u thá»§ ( 34.8%)\n",
      "   FW      : 3193 cáº§u thá»§ ( 15.4%)\n",
      "   GK      : 2138 cáº§u thá»§ ( 10.3%)\n",
      "   UNKNOWN :   23 cáº§u thá»§ (  0.1%)\n"
     ]
    }
   ],
   "source": [
    "print(\"PHÃ‚N LOáº I Vá»Š TRÃ Cáº¦U THá»¦\")\n",
    "\n",
    "def classify_position(pos):\n",
    "    \"\"\"PhÃ¢n loáº¡i vá»‹ trÃ­ cáº§u thá»§ thÃ nh 4 nhÃ³m chÃ­nh\"\"\"\n",
    "    if pd.isna(pos):\n",
    "        return 'UNKNOWN'\n",
    "    pos = str(pos).upper()\n",
    "    if 'GK' in pos:\n",
    "        return 'GK'\n",
    "    elif any(x in pos for x in ['DF', 'CB', 'LB', 'RB', 'WB']):\n",
    "        return 'DF'\n",
    "    elif any(x in pos for x in ['MF', 'CM', 'DM', 'AM']):\n",
    "        return 'MF'\n",
    "    elif any(x in pos for x in ['FW', 'ST', 'CF', 'LW', 'RW']):\n",
    "        return 'FW'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "df['position_category'] = df['position'].apply(classify_position)\n",
    "\n",
    "print(\"\\n- PhÃ¢n bá»‘ vá»‹ trÃ­:\")\n",
    "for pos, count in df['position_category'].value_counts().items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   {pos:8s}: {count:4d} cáº§u thá»§ ({pct:5.1f}%)\")\n",
    "\n",
    "# Táº¡o indicator columns\n",
    "position_categories = ['GK', 'DF', 'MF', 'FW']\n",
    "for pos in position_categories:\n",
    "    df[f'is_{pos}'] = (df['position_category'] == pos).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6017af9",
   "metadata": {},
   "source": [
    "#### **3. PhÃ¢n tÃ­ch Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5e1e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CÃC Cá»˜T CÃ“ MISSING > 5%:\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”´ penalty_save_pct                             :  96.85%\n",
      "ðŸ”´ avg_pass_length                              :  95.81%\n",
      "ðŸ”´ wins_per90                                   :  95.81%\n",
      "ðŸ”´ def_actions_outside_pen_per90                :  95.81%\n",
      "ðŸ”´ shots_on_target_against_per90                :  95.81%\n",
      "ðŸ”´ saves_per90                                  :  95.81%\n",
      "ðŸ”´ save_percentage                              :  95.81%\n",
      "ðŸ”´ avg_distance_def_actions                     :  95.81%\n",
      "ðŸ”´ crosses_stopped_pct                          :  95.81%\n",
      "ðŸ”´ clean_sheet_pct                              :  95.81%\n",
      "ðŸ”´ goals_against_per90                          :  95.81%\n",
      "ðŸ”´ draws_per90                                  :  95.81%\n",
      "ðŸ”´ losses_per90                                 :  95.81%\n",
      "ðŸ”´ psxg_per_shot                                :  95.81%\n",
      "ðŸ”´ psxg_ga_per90                                :  95.81%\n",
      "ðŸ”´ launch_pct                                   :  95.81%\n",
      "ðŸ”´ passes_attempted_per90                       :  95.81%\n",
      "ðŸŸ¡ take_on_success_pct                          :  53.98%\n",
      "ðŸŸ¡ avg_shot_distance                            :  53.91%\n",
      "ðŸŸ¡ shots_on_target_pct                          :  53.91%\n"
     ]
    }
   ],
   "source": [
    "missing_analysis = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Pct': (df.isnull().sum().values / len(df) * 100)\n",
    "})\n",
    "missing_analysis['Data_Type'] = missing_analysis['Column'].apply(lambda x: str(df[x].dtype))\n",
    "missing_analysis = missing_analysis.sort_values('Missing_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nCÃC Cá»˜T CÃ“ MISSING > 5%:\")\n",
    "print(\"-\" * 80)\n",
    "high_missing = missing_analysis[missing_analysis['Missing_Pct'] > 5]\n",
    "\n",
    "for idx, row in high_missing.head(20).iterrows():\n",
    "    status = \"ðŸ”´\" if row['Missing_Pct'] > 80 else \"ðŸŸ¡\" if row['Missing_Pct'] > 50 else \"ðŸŸ¢\"\n",
    "    print(f\"{status} {row['Column']:45s}: {row['Missing_Pct']:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345f376",
   "metadata": {},
   "source": [
    "#### **4. PhÃ¢n tÃ­ch Correlation - PhÃ¡t hiá»‡n trÃ¹ng láº·p**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ea3959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CÃC Cáº¶P Cá»˜T CÃ“ CORRELATION CAO (> 0.90):\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”´ goals_per_90                        <-> def_actions_outside_pen_per90      : -0.9995\n",
      "ðŸ”´ goals_per_90                        <-> saves_per90                        :  0.9938\n",
      "ðŸ”´ goals_per_90                        <-> avg_distance_def_actions           : -0.9916\n",
      "ðŸ”´ goals_per_90                        <-> clean_sheet_pct                    :  0.9881\n",
      "ðŸ”´ launch_pct                          <-> avg_pass_length                    :  0.9771\n",
      "ðŸ”´ goals_per_90                        <-> losses_per90                       :  0.9732\n",
      "ðŸ”´ npxg_per90                          <-> xg_per90                           :  0.9656\n",
      "ðŸ”´ passes_completed_per90              <-> touches_per90                      :  0.9612\n",
      "ðŸŸ¡ goals_per_90                        <-> psxg_ga_per90                      :  0.9497\n",
      "ðŸŸ¡ carries_per90                       <-> passes_received_per90              :  0.9496\n",
      "ðŸŸ¡ appearances                         <-> minutes_played                     :  0.9289\n",
      "ðŸŸ¡ goals_per_90                        <-> save_percentage                    :  0.9268\n",
      "ðŸŸ¡ passes_completed_per90              <-> passes_received_per90              :  0.9070\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude_from_corr = ['market_value'] + [f'is_{pos}' for pos in position_categories]\n",
    "numeric_cols_for_corr = [c for c in numeric_cols if c not in exclude_from_corr]\n",
    "\n",
    "# TÃ­nh correlation matrix\n",
    "corr_matrix = df[numeric_cols_for_corr].corr()\n",
    "\n",
    "# TÃ¬m cÃ¡c cáº·p cÃ³ correlation cao (> 0.9)\n",
    "print(\"\\nCÃC Cáº¶P Cá»˜T CÃ“ CORRELATION CAO (> 0.90):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.90:\n",
    "            col1 = corr_matrix.columns[i]\n",
    "            col2 = corr_matrix.columns[j]\n",
    "            high_corr_pairs.append({\n",
    "                'Column_1': col1,\n",
    "                'Column_2': col2,\n",
    "                'Correlation': corr_val\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', \n",
    "                                                              ascending=False, \n",
    "                                                              key=abs)\n",
    "    for idx, row in high_corr_df.iterrows():\n",
    "        emoji = \"ðŸ”´\" if abs(row['Correlation']) > 0.95 else \"ðŸŸ¡\"\n",
    "        print(f\"{emoji} {row['Column_1']:35s} <-> {row['Column_2']:35s}: {row['Correlation']:7.4f}\")\n",
    "else:\n",
    "    print(\"- KhÃ´ng cÃ³ cáº·p nÃ o cÃ³ correlation > 0.90\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba923c",
   "metadata": {},
   "source": [
    "#### **5. PhÃ¢n tÃ­ch Correlation vá»›i Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cee183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- TOP 15 FEATURES TÆ¯Æ NG QUAN CAO NHáº¤T Vá»šI MARKET_VALUE:\n",
      "--------------------------------------------------------------------------------\n",
      " 1.    ðŸ“ˆ goals                                        :  0.2567\n",
      " 2.    ðŸ“ˆ assists                                      :  0.2418\n",
      " 3.    ðŸ“ˆ wins_per90                                   :  0.2282\n",
      " 4.    ðŸ“ˆ minutes_played                               :  0.2027\n",
      " 5.    ðŸ“ˆ appearances                                  :  0.2005\n",
      " 6.    ðŸ“ˆ passes_received_per90                        :  0.1933\n",
      " 7.    ðŸ“ˆ touches_att_pen_per90                        :  0.1878\n",
      " 8.    ðŸ“ˆ npxg_xag_per90                               :  0.1865\n",
      " 9.    ðŸ“ˆ gca_per90                                    :  0.1777\n",
      "10.    ðŸ“ˆ touches_att_third_per90                      :  0.1768\n",
      "11.    ðŸ“‰ losses_per90                                 : -0.1755\n",
      "12.    ðŸ“ˆ carries_per90                                :  0.1691\n",
      "13.    ðŸ“‰ goals_against_per90                          : -0.1662\n",
      "14.    ðŸ“ˆ npg_per90                                    :  0.1636\n",
      "15.    ðŸ“ˆ xag_per90                                    :  0.1623\n"
     ]
    }
   ],
   "source": [
    "target_corr = {}\n",
    "for col in numeric_cols_for_corr:\n",
    "    valid_data = df[[col, 'market_value']].dropna()\n",
    "    if len(valid_data) > 30:\n",
    "        corr = valid_data[col].corr(valid_data['market_value'])\n",
    "        target_corr[col] = corr\n",
    "\n",
    "# Sáº¯p xáº¿p theo absolute correlation\n",
    "target_corr_sorted = sorted(target_corr.items(), \n",
    "                           key=lambda x: abs(x[1]), \n",
    "                           reverse=True)\n",
    "\n",
    "print(\"\\n- TOP 15 FEATURES TÆ¯Æ NG QUAN CAO NHáº¤T Vá»šI MARKET_VALUE:\")\n",
    "print(\"-\" * 80)\n",
    "for i, (col, corr) in enumerate(target_corr_sorted[:15], 1):\n",
    "    emoji = \"ðŸ“ˆ\" if corr > 0 else \"ðŸ“‰\"\n",
    "    strength = \"Strong: \" if abs(corr) > 0.5 else \"Medium\" if abs(corr) > 0.3 else \"  \"\n",
    "    print(f\"{i:2d}. {strength} {emoji} {col:45s}: {corr:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00956343",
   "metadata": {},
   "source": [
    "#### **6. PhÃ¢n tÃ­ch VIF (Multicollinearity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "727a0bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- TÃ­nh VIF trÃªn 11035 samples vá»›i 9 features\n",
      "(VIF > 10: multicollinearity cao, VIF > 100: cá»±c ká»³ cao)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "TOP 15 VIF CAO NHáº¤T:\n",
      "ðŸ”´   height                                       :      62.69\n",
      "ðŸ”´   minutes_played                               :      54.68\n",
      "ðŸŸ¡   appearances                                  :      48.69\n",
      "ðŸŸ¡   age                                          :      38.22\n",
      "ðŸŸ¡   minutes_per_game                             :      36.53\n",
      "âœ…   goals                                        :       4.05\n",
      "âœ…   assists                                      :       3.87\n",
      "âœ…   goals_per_90                                 :       3.67\n",
      "âœ…   assists_per_90                               :       2.92\n",
      "\n",
      "THá»NG KÃŠ VIF:\n",
      "   - VIF > 100 (Cá»±c cao): 0 cá»™t\n",
      "   - VIF 10-100 (Cao): 5 cá»™t\n",
      "   - VIF < 10 (OK): 4 cá»™t\n"
     ]
    }
   ],
   "source": [
    "cols_for_vif = [col for col in numeric_cols_for_corr \n",
    "                if df[col].isnull().sum() / len(df) < 0.5][:30]\n",
    "\n",
    "df_vif = df[cols_for_vif].dropna()\n",
    "\n",
    "if len(df_vif) > 10 and len(cols_for_vif) > 1:\n",
    "    print(f\"\\n- TÃ­nh VIF trÃªn {len(df_vif)} samples vá»›i {len(cols_for_vif)} features\")\n",
    "    print(\"(VIF > 10: multicollinearity cao, VIF > 100: cá»±c ká»³ cao)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    try:\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"Feature\"] = cols_for_vif\n",
    "        vif_data[\"VIF\"] = [variance_inflation_factor(df_vif.values, i) \n",
    "                          for i in range(len(cols_for_vif))]\n",
    "        vif_data = vif_data.sort_values('VIF', ascending=False)\n",
    "        \n",
    "        # Hiá»ƒn thá»‹ top 15\n",
    "        print(\"\\nTOP 15 VIF CAO NHáº¤T:\")\n",
    "        for idx, row in vif_data.head(15).iterrows():\n",
    "            if row['VIF'] > 100:\n",
    "                status = \"ðŸ”´ðŸ”´\"\n",
    "            elif row['VIF'] > 50:\n",
    "                status = \"ðŸ”´  \"\n",
    "            elif row['VIF'] > 10:\n",
    "                status = \"ðŸŸ¡  \"\n",
    "            else:\n",
    "                status = \"âœ…  \"\n",
    "            print(f\"{status} {row['Feature']:45s}: {row['VIF']:10.2f}\")\n",
    "        \n",
    "        # Thá»‘ng kÃª\n",
    "        print(f\"\\nTHá»NG KÃŠ VIF:\")\n",
    "        print(f\"   - VIF > 100 (Cá»±c cao): {len(vif_data[vif_data['VIF'] > 100])} cá»™t\")\n",
    "        print(f\"   - VIF 10-100 (Cao): {len(vif_data[(vif_data['VIF'] > 10) & (vif_data['VIF'] <= 100)])} cá»™t\")\n",
    "        print(f\"   - VIF < 10 (OK): {len(vif_data[vif_data['VIF'] <= 10])} cá»™t\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"- KhÃ´ng thá»ƒ tÃ­nh VIF: {str(e)}\")\n",
    "        vif_data = None\n",
    "else:\n",
    "    print(\"-  KhÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ tÃ­nh VIF\")\n",
    "    vif_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7fc3e4",
   "metadata": {},
   "source": [
    "#### **7. PhÃ¢n tÃ­ch cÃ¡c cá»™t dáº«n xuáº¥t**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64be5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kiá»ƒm tra cÃ¡c cá»™t cÃ³ thá»ƒ tÃ­nh tá»« cá»™t khÃ¡c:\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ minutes_per_game = minutes_played / appearances (corr: 1.0000)\n",
      "âœ“ npxg_xag_per90 = npxg_per90 + xag_per90 (corr: 0.9987)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKiá»ƒm tra cÃ¡c cá»™t cÃ³ thá»ƒ tÃ­nh tá»« cá»™t khÃ¡c:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "derived_candidates = []\n",
    "\n",
    "# Check minutes_per_game\n",
    "if all(col in df.columns for col in ['minutes_per_game', 'minutes_played', 'appearances']):\n",
    "    df['calculated_mpg'] = df['minutes_played'] / df['appearances'].replace(0, 1)\n",
    "    valid = df[['minutes_per_game', 'calculated_mpg']].dropna()\n",
    "    if len(valid) > 10:\n",
    "        correlation = valid['minutes_per_game'].corr(valid['calculated_mpg'])\n",
    "        if abs(correlation) > 0.99:\n",
    "            derived_candidates.append({\n",
    "                'Column': 'minutes_per_game',\n",
    "                'Derived_From': 'minutes_played / appearances',\n",
    "                'Correlation': correlation\n",
    "            })\n",
    "            print(f\"âœ“ minutes_per_game = minutes_played / appearances (corr: {correlation:.4f})\")\n",
    "\n",
    "# Check cÃ¡c metrics tá»•ng há»£p\n",
    "potential_sums = [\n",
    "    ('npxg_xag_per90', ['npxg_per90', 'xag_per90']),\n",
    "]\n",
    "\n",
    "for target_col, source_cols in potential_sums:\n",
    "    if target_col in df.columns and all(col in df.columns for col in source_cols):\n",
    "        df['calculated_sum'] = df[source_cols].sum(axis=1)\n",
    "        valid_data = df[[target_col, 'calculated_sum']].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            correlation = valid_data[target_col].corr(valid_data['calculated_sum'])\n",
    "            if abs(correlation) > 0.95:\n",
    "                derived_candidates.append({\n",
    "                    'Column': target_col,\n",
    "                    'Derived_From': ' + '.join(source_cols),\n",
    "                    'Correlation': correlation\n",
    "                })\n",
    "                print(f\"âœ“ {target_col} = {' + '.join(source_cols)} (corr: {correlation:.4f})\")\n",
    "\n",
    "if not derived_candidates:\n",
    "    print(\"- KhÃ´ng tÃ¬m tháº¥y cá»™t derived rÃµ rÃ ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193dea9",
   "metadata": {},
   "source": [
    "#### **8. Táº¡o Recommendation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b211801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- DANH SÃCH Äá»€ XUáº¤T LOáº I Bá»Ž:\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¸ HIGH MISSING (17 cá»™t):\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”´ penalty_save_pct                             : Missing 96.8%\n",
      "ðŸ”´ avg_pass_length                              : Missing 95.8%\n",
      "ðŸ”´ wins_per90                                   : Missing 95.8%\n",
      "ðŸ”´ def_actions_outside_pen_per90                : Missing 95.8%\n",
      "ðŸ”´ shots_on_target_against_per90                : Missing 95.8%\n",
      "ðŸ”´ saves_per90                                  : Missing 95.8%\n",
      "ðŸ”´ save_percentage                              : Missing 95.8%\n",
      "ðŸ”´ avg_distance_def_actions                     : Missing 95.8%\n",
      "ðŸ”´ crosses_stopped_pct                          : Missing 95.8%\n",
      "ðŸ”´ clean_sheet_pct                              : Missing 95.8%\n",
      "ðŸ”´ goals_against_per90                          : Missing 95.8%\n",
      "ðŸ”´ draws_per90                                  : Missing 95.8%\n",
      "ðŸ”´ losses_per90                                 : Missing 95.8%\n",
      "ðŸ”´ psxg_per_shot                                : Missing 95.8%\n",
      "ðŸ”´ psxg_ga_per90                                : Missing 95.8%\n",
      "ðŸ”´ launch_pct                                   : Missing 95.8%\n",
      "ðŸ”´ passes_attempted_per90                       : Missing 95.8%\n",
      "\n",
      "ðŸ”¸ LOW CORRELATION (6 cá»™t):\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸŸ¢ height                                       : Low correlation: 0.0151\n",
      "ðŸŸ¢ assists_per_90                               : Low correlation: 0.0078\n",
      "ðŸŸ¢ take_on_success_pct                          : Low correlation: -0.0283\n",
      "ðŸŸ¢ tackles_per90                                : Low correlation: -0.0251\n",
      "ðŸŸ¢ aerial_win_pct                               : Low correlation: -0.0072\n",
      "ðŸŸ¢ red_cards_per90                              : Low correlation: -0.0268\n",
      "\n",
      "ðŸ”¸ DERIVED (2 cá»™t):\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸŸ¡ minutes_per_game                             : Derived from minutes_played / appearances\n",
      "ðŸŸ¡ npxg_xag_per90                               : Derived from npxg_per90 + xag_per90\n",
      "\n",
      "ðŸ”¸ DUPLICATE (8 cá»™t):\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”´ goals_per_90                                 : Duplicate vá»›i saves_per90 (corr: 0.9938)\n",
      "ðŸ”´ goals_per_90                                 : Duplicate vá»›i clean_sheet_pct (corr: 0.9881)\n",
      "ðŸ”´ def_actions_outside_pen_per90                : Duplicate vá»›i goals_per_90 (corr: -0.9995)\n",
      "ðŸ”´ avg_distance_def_actions                     : Duplicate vá»›i goals_per_90 (corr: -0.9916)\n",
      "ðŸ”´ goals_per_90                                 : Duplicate vá»›i losses_per90 (corr: 0.9732)\n",
      "ðŸ”´ npxg_per90                                   : Duplicate vá»›i xg_per90 (corr: 0.9656)\n",
      "ðŸ”´ touches_per90                                : Duplicate vá»›i passes_completed_per90 (corr: 0.9612)\n",
      "ðŸ”´ avg_pass_length                              : Duplicate vá»›i launch_pct (corr: 0.9771)\n",
      "\n",
      "ðŸ”¸ METADATA (3 cá»™t):\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸŸ¡ player_id                                    : Metadata khÃ´ng cáº§n cho modeling\n",
      "ðŸŸ¡ player_name                                  : Metadata khÃ´ng cáº§n cho modeling\n",
      "ðŸŸ¡ foot                                         : Metadata khÃ´ng cáº§n cho modeling\n",
      "\n",
      "- Tá»”NG Káº¾T PHÃ‚N TÃCH:\n",
      "   - Tá»•ng sá»‘ cá»™t hiá»‡n táº¡i: 77\n",
      "   - Äá» xuáº¥t loáº¡i bá»: 36 cá»™t\n",
      "   - CÃ²n láº¡i dá»± kiáº¿n: 41 cá»™t\n"
     ]
    }
   ],
   "source": [
    "recommendations = {\n",
    "    'high_missing': [],\n",
    "    'low_correlation': [],\n",
    "    'high_vif': [],\n",
    "    'derived': [],\n",
    "    'duplicate': [],\n",
    "    'metadata': []\n",
    "}\n",
    "\n",
    "# 1. Missing quÃ¡ cao (> 90%)\n",
    "for idx, row in missing_analysis.iterrows():\n",
    "    if row['Missing_Pct'] > 90:\n",
    "        recommendations['high_missing'].append({\n",
    "            'column': row['Column'],\n",
    "            'reason': f\"Missing {row['Missing_Pct']:.1f}%\",\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "\n",
    "# 2. Correlation tháº¥p vá»›i target (< 0.03)\n",
    "for col, corr in target_corr.items():\n",
    "    if abs(corr) < 0.03:\n",
    "        recommendations['low_correlation'].append({\n",
    "            'column': col,\n",
    "            'reason': f\"Low correlation: {corr:.4f}\",\n",
    "            'priority': 'LOW'\n",
    "        })\n",
    "\n",
    "# 3. VIF cao\n",
    "if vif_data is not None:\n",
    "    for idx, row in vif_data.iterrows():\n",
    "        if row['VIF'] > 70:\n",
    "            recommendations['high_vif'].append({\n",
    "                'column': row['Feature'],\n",
    "                'reason': f\"VIF = {row['VIF']:.1f}\",\n",
    "                'priority': 'HIGH'\n",
    "            })\n",
    "\n",
    "# 4. Derived columns\n",
    "for item in derived_candidates:\n",
    "    recommendations['derived'].append({\n",
    "        'column': item['Column'],\n",
    "        'reason': f\"Derived from {item['Derived_From']}\",\n",
    "        'priority': 'MEDIUM'\n",
    "    })\n",
    "\n",
    "# 5. Duplicate (corr > 0.95)\n",
    "for item in high_corr_pairs:\n",
    "    if abs(item['Correlation']) > 0.95:\n",
    "        corr1 = abs(target_corr.get(item['Column_1'], 0))\n",
    "        corr2 = abs(target_corr.get(item['Column_2'], 0))\n",
    "        \n",
    "        to_drop = item['Column_1'] if corr1 < corr2 else item['Column_2']\n",
    "        to_keep = item['Column_2'] if corr1 < corr2 else item['Column_1']\n",
    "        \n",
    "        recommendations['duplicate'].append({\n",
    "            'column': to_drop,\n",
    "            'reason': f\"Duplicate vá»›i {to_keep} (corr: {item['Correlation']:.4f})\",\n",
    "            'priority': 'HIGH'\n",
    "        })\n",
    "\n",
    "# 6. Metadata\n",
    "metadata_cols = ['player_id', 'player_name', 'foot']\n",
    "for col in metadata_cols:\n",
    "    if col in df.columns:\n",
    "        recommendations['metadata'].append({\n",
    "            'column': col,\n",
    "            'reason': 'Metadata khÃ´ng cáº§n cho modeling',\n",
    "            'priority': 'MEDIUM'\n",
    "        })\n",
    "\n",
    "# In recommendations\n",
    "print(\"\\n- DANH SÃCH Äá»€ XUáº¤T LOáº I Bá»Ž:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_to_drop = 0\n",
    "columns_to_drop = []\n",
    "\n",
    "for category, items in recommendations.items():\n",
    "    if items:\n",
    "        print(f\"\\nðŸ”¸ {category.upper().replace('_', ' ')} ({len(items)} cá»™t):\")\n",
    "        print(\"-\" * 80)\n",
    "        for item in items:\n",
    "            priority_emoji = \"ðŸ”´\" if item['priority'] == 'HIGH' else \"ðŸŸ¡\" if item['priority'] == 'MEDIUM' else \"ðŸŸ¢\"\n",
    "            print(f\"{priority_emoji} {item['column']:45s}: {item['reason']}\")\n",
    "            columns_to_drop.append(item['column'])\n",
    "            total_to_drop += 1\n",
    "\n",
    "print(f\"\\n- Tá»”NG Káº¾T PHÃ‚N TÃCH:\")\n",
    "print(f\"   - Tá»•ng sá»‘ cá»™t hiá»‡n táº¡i: {len(df.columns)}\")\n",
    "print(f\"   - Äá» xuáº¥t loáº¡i bá»: {total_to_drop} cá»™t\")\n",
    "print(f\"   - CÃ²n láº¡i dá»± kiáº¿n: {len(df.columns) - total_to_drop} cá»™t\")\n",
    "\n",
    "# LÆ°u recommendations\n",
    "all_recommendations = []\n",
    "for category, items in recommendations.items():\n",
    "    for item in items:\n",
    "        all_recommendations.append({\n",
    "            'Category': category,\n",
    "            'Column': item['column'],\n",
    "            'Reason': item['reason'],\n",
    "            'Priority': item['priority']\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd1464",
   "metadata": {},
   "source": [
    "#### **9. Loáº¡i bá» cÃ¡c cá»™t**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b5e0c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ÄÃ£ loáº¡i bá»: 31 cá»™t\n",
      "- Dataset sau khi lÃ m sáº¡ch: (20682, 46)\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = list(set(columns_to_drop))\n",
    "columns_to_drop_exist = [col for col in columns_to_drop if col in df.columns]\n",
    "\n",
    "df_cleaned = df.drop(columns=columns_to_drop_exist)\n",
    "\n",
    "print(f\"- ÄÃ£ loáº¡i bá»: {len(columns_to_drop_exist)} cá»™t\")\n",
    "print(f\"- Dataset sau khi lÃ m sáº¡ch: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29107516",
   "metadata": {},
   "source": [
    "#### **10. PhÃ¢n tÃ­ch Missing Values theo vá»‹ trÃ­**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2999e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Tá»· lá»‡ missing cá»§a features theo vá»‹ trÃ­:\n",
      "\n",
      "\n",
      "GK (2138 cáº§u thá»§):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "DF (7192 cáº§u thá»§):\n",
      "----------------------------------------------------------------------\n",
      "   âš ï¸ interceptions_per90                          :  42.7%\n",
      "   âš ï¸ blocks_per90                                 :  42.7%\n",
      "   âš ï¸ ball_recoveries_per90                        :  42.7%\n",
      "   âš ï¸ aerials_won_per90                            :  42.7%\n",
      "\n",
      "MF (8136 cáº§u thá»§):\n",
      "----------------------------------------------------------------------\n",
      "   âš ï¸ key_passes_per90                             :  44.4%\n",
      "   âš ï¸ sca_per90                                    :  44.4%\n",
      "   âš ï¸ gca_per90                                    :  44.4%\n",
      "   âš ï¸ xag_per90                                    :  44.4%\n",
      "\n",
      "FW (3193 cáº§u thá»§):\n",
      "----------------------------------------------------------------------\n",
      "   âŒ npg_per90                                    :  61.4%\n",
      "   âŒ xag_per90                                    :  61.4%\n",
      "   âŒ sca_per90                                    :  61.4%\n",
      "   âŒ gca_per90                                    :  61.4%\n"
     ]
    }
   ],
   "source": [
    "POSITION_SPECIFIC_COLS = {\n",
    "    'GK': [\n",
    "        'goals_against_per90', 'shots_on_target_against_per90', 'saves_per90',\n",
    "        'save_percentage', 'clean_sheet_pct', 'psxg_per_shot', 'psxg_ga_per90',\n",
    "        'penalty_save_pct', 'launch_pct', 'avg_pass_length',\n",
    "        'def_actions_outside_pen_per90', 'avg_distance_def_actions', \n",
    "        'crosses_stopped_pct'\n",
    "    ],\n",
    "    'DF': [\n",
    "        'tackles_per90', 'interceptions_per90', 'blocks_per90',\n",
    "        'ball_recoveries_per90', 'aerials_won_per90', 'aerial_win_pct'\n",
    "    ],\n",
    "    'MF': [\n",
    "        'key_passes_per90', 'sca_per90', 'gca_per90',\n",
    "        'xag_per90', 'assists_per_90'\n",
    "    ],\n",
    "    'FW': [\n",
    "        'goals_per_90', 'assists_per_90', 'npg_per90', \n",
    "        'npxg_per90', 'xag_per90', 'sca_per90', 'gca_per90'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n- Tá»· lá»‡ missing cá»§a features theo vá»‹ trÃ­:\\n\")\n",
    "\n",
    "for pos in position_categories:\n",
    "    df_pos = df_cleaned[df_cleaned['position_category'] == pos]\n",
    "    \n",
    "    if len(df_pos) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{pos} ({len(df_pos)} cáº§u thá»§):\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if pos in POSITION_SPECIFIC_COLS:\n",
    "        for col in POSITION_SPECIFIC_COLS[pos]:\n",
    "            if col in df_cleaned.columns:\n",
    "                missing_pct = df_pos[col].isna().sum() / len(df_pos) * 100\n",
    "                status = \"âœ…\" if missing_pct < 30 else \"âš ï¸\" if missing_pct < 60 else \"âŒ\"\n",
    "                print(f\"   {status} {col:45s}: {missing_pct:5.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd438a8d",
   "metadata": {},
   "source": [
    "#### **11. Xá»­ lÃ­ Market Value Missing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd2d6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Market value missing: 4229 (20.4%)\n",
      "ÄÃ£ loáº¡i bá» 4229 dÃ²ng\n",
      "Dataset cÃ²n láº¡i: 16453 cáº§u thá»§\n"
     ]
    }
   ],
   "source": [
    "market_value_missing = df_cleaned['market_value'].isna().sum()\n",
    "print(f\"\\n- Market value missing: {market_value_missing} ({market_value_missing/len(df_cleaned)*100:.1f}%)\")\n",
    "\n",
    "if market_value_missing > 0:\n",
    "    df_cleaned = df_cleaned.dropna(subset=['market_value']).copy()\n",
    "    print(f\"ÄÃ£ loáº¡i bá» {market_value_missing} dÃ²ng\")\n",
    "    print(f\"Dataset cÃ²n láº¡i: {len(df_cleaned)} cáº§u thá»§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff4fea",
   "metadata": {},
   "source": [
    "#### **12. Impute missing values theo vá»‹ trÃ­**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2fb0655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Impute 36 numeric columns theo median cá»§a tá»«ng vá»‹ trÃ­\n",
      "\n",
      "GK:\n",
      "   - Imputed 7 columns\n",
      "   - Missing: 30 â†’ 0\n",
      "DF:\n",
      "   - Imputed 36 columns\n",
      "   - Missing: 57,170 â†’ 0\n",
      "MF:\n",
      "   - Imputed 36 columns\n",
      "   - Missing: 68,430 â†’ 0\n",
      "FW:\n",
      "   - Imputed 36 columns\n",
      "   - Missing: 34,283 â†’ 0\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['nationality', 'position', 'position_category', \n",
    "                   'current_club', 'league']\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude_from_impute = ['market_value'] + [f'is_{p}' for p in position_categories]\n",
    "cols_to_impute = [c for c in numeric_cols if c not in exclude_from_impute]\n",
    "\n",
    "print(f\"\\n- Impute {len(cols_to_impute)} numeric columns theo median cá»§a tá»«ng vá»‹ trÃ­\\n\")\n",
    "\n",
    "for pos in position_categories:\n",
    "    mask = df_cleaned['position_category'] == pos\n",
    "    df_pos = df_cleaned[mask]\n",
    "    \n",
    "    if len(df_pos) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"{pos}:\")\n",
    "    \n",
    "    # Impute báº±ng median\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    cols_with_data = [col for col in cols_to_impute \n",
    "                      if df_pos[col].notna().sum() > 0]\n",
    "    \n",
    "    before_missing = df_cleaned.loc[mask, cols_with_data].isnull().sum().sum()\n",
    "    \n",
    "    if cols_with_data:\n",
    "        imputed_values = imputer.fit_transform(df_pos[cols_with_data])\n",
    "        df_cleaned.loc[mask, cols_with_data] = imputed_values\n",
    "    \n",
    "    # Fill 0 cho cá»™t toÃ n NULL\n",
    "    cols_all_null = [col for col in cols_to_impute \n",
    "                     if df_pos[col].notna().sum() == 0]\n",
    "    \n",
    "    if cols_all_null:\n",
    "        df_cleaned.loc[mask, cols_all_null] = 0\n",
    "    \n",
    "    after_missing = df_cleaned.loc[mask, cols_with_data].isnull().sum().sum()\n",
    "    \n",
    "    print(f\"   - Imputed {len(cols_with_data)} columns\")\n",
    "    print(f\"   - Missing: {before_missing:,} â†’ {after_missing:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5908ed8",
   "metadata": {},
   "source": [
    "#### **13. LÆ°u táº­p dá»¯ liá»‡u**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17a79459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to: output\\football_players_dataset.csv\n",
      "   - Rows: 16,453\n",
      "   - Columns: 46\n"
     ]
    }
   ],
   "source": [
    "# Sáº¯p xáº¿p cá»™t\n",
    "column_order = (\n",
    "    ['age', 'height', 'nationality', 'position', 'position_category', \n",
    "     'current_club', 'league', 'appearances', 'minutes_played'] +\n",
    "    [f'is_{pos}' for pos in position_categories] +\n",
    "    ['age_group', 'experience_level', 'minutes_per_appearance']\n",
    ")\n",
    "\n",
    "numeric_features = df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features = [c for c in numeric_features \n",
    "                   if c not in column_order and c != 'market_value']\n",
    "column_order.extend(numeric_features)\n",
    "column_order.append('market_value')\n",
    "\n",
    "column_order = [col for col in column_order if col in df_cleaned.columns]\n",
    "df_final = df_cleaned[column_order]\n",
    "\n",
    "output_folder = os.path.dirname(FINAL_OUTPUT_FILE)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# LÆ°u file\n",
    "df_final.to_csv(FINAL_OUTPUT_FILE, index=False)\n",
    "\n",
    "# In thÃ´ng tin\n",
    "print(f\"\\nSaved to: {FINAL_OUTPUT_FILE}\")\n",
    "print(f\"   - Rows: {len(df_final):,}\")\n",
    "print(f\"   - Columns: {len(df_final.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
