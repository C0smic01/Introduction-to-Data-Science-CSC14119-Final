{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1de0228",
   "metadata": {},
   "source": [
    "# DATA COLLECTION NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b9786",
   "metadata": {},
   "source": [
    "###  **1. Nguồn thu thập dữ liệu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9261bab",
   "metadata": {},
   "source": [
    "#### **1.1 [Fbref](https://fbref.com/en/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0e16c",
   "metadata": {},
   "source": [
    "**FBref** là một trang web chuyên cung cấp dữ liệu và thống kê chi tiết về bóng đá. Đây là một trong những nguồn dữ liệu uy tín nhất dành cho người hâm mộ bóng đá, nhà phân tích dữ liệu, nhà báo thể thao và các nhà nghiên cứu.\n",
    "\n",
    "Các dữ liệu có thể thu thập được từ trang web này:\n",
    "\n",
    "| Trường dữ liệu             | Mô tả                             |\n",
    "|----------------------------|-----------------------------------|\n",
    "| player_name                | Tên cầu thủ                       |\n",
    "| age                        | Tuổi                              |\n",
    "| nationality                | Quốc tịch                         |\n",
    "| height                     | Chiều cao                         |\n",
    "| foot                       | Chân thuận                        |\n",
    "| position                   | Vị trí thi đấu                    |\n",
    "| current_club               | Câu lạc bộ hiện tại               |\n",
    "| league                     | Giải đấu                          |\n",
    "| market_value               | Giá trị chuyển nhượng             |\n",
    "| appearances                | Số trận thi đấu                   |\n",
    "| minutes_played             | Tổng phút thi đấu                 |\n",
    "| minutes_per_game           | Phút thi đấu trung bình/trận      |\n",
    "| goals                      | Bàn thắng                         |\n",
    "| assists                    | Kiến tạo                          |\n",
    "| goals_per_90               | Bàn thắng mỗi 90 phút             |\n",
    "| assists_per_90             | Kiến tạo mỗi 90 phút              |\n",
    "| shots                      | Tổng cú sút                       |\n",
    "| shots_on_target            | Cú sút trúng đích                 |\n",
    "| xG                         | Expected Goals (bàn thắng kỳ vọng)|\n",
    "| xAG                        | Expected Assists (kiến tạo kỳ vọng) |\n",
    "| key_passes                 | Đường chuyền tạo cơ hội           |\n",
    "| tackles                    | Số pha tắc bóng                   |\n",
    "| interceptions              | Số lần cắt bóng                   |\n",
    "| clearances                 | Phá bóng                          |\n",
    "| aerial_wins                | Thắng tranh chấp trên không       |\n",
    "| aerial_win_rate            | Tỷ lệ thắng không chiến           |\n",
    "| clean_sheets               | Giữ sạch lưới                     |\n",
    "| saves                      | Cứu thua                           |\n",
    "| save_percentage            | Tỷ lệ cứu thua                     |\n",
    "| goals_conceded             | Bàn thua                           |\n",
    "| goals_conceded_per_90      | Bàn thua mỗi 90 phút               |\n",
    "| psxg_minus_ga              | PSxG − GA (hiệu suất thủ môn)     |\n",
    "| passes_completed           | Đường chuyền chính xác            |\n",
    "| pass_accuracy              | Tỷ lệ chính xác chuyền bóng       |\n",
    "| progressive_passes         | Đường chuyền tiến tuyến           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7a9f2",
   "metadata": {},
   "source": [
    "#### **1.2. [Transfermart](https://www.transfermarkt.co.uk/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ee422",
   "metadata": {},
   "source": [
    "**Transfermarkt** là trang web chuyên cung cấp thông tin về bóng đá, nổi bật với dữ liệu về giá trị chuyển nhượng cầu thủ, hồ sơ cầu thủ, thành tích đội bóng, bảng xếp hạng giải đấu và thống kê thi đấu cơ bản. Trang web được sử dụng rộng rãi để tham khảo giá trị thị trường cầu thủ, so sánh cầu thủ, và phân tích dữ liệu bóng đá.\n",
    "\n",
    "Các dữ liệu có thể thu thập được từ trang web này:\n",
    "\n",
    "| Trường dữ liệu             | Mô tả                             |\n",
    "|----------------------------|-----------------------------------|\n",
    "| market_value               | Giá trị chuyển nhượng cầu thủ     |\n",
    "| height                     | Chiều cao (nếu thiếu dữ liệu từ Fbref)                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83354c6",
   "metadata": {},
   "source": [
    "### **2. Mã nguồn (Source code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a362446",
   "metadata": {},
   "source": [
    "##### **Cài đặt các thư viện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531d6e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (2.31.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.12.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: selenium>=4.15.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (4.38.0)\n",
      "Requirement already satisfied: webdriver-manager>=4.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->-r requirements.txt (line 1)) (2025.10.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4>=4.12.0->-r requirements.txt (line 3)) (2.8)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium>=4.15.0->-r requirements.txt (line 4)) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium>=4.15.0->-r requirements.txt (line 4)) (0.12.2)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium>=4.15.0->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium>=4.15.0->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium>=4.15.0->-r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium>=4.15.0->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium>=4.15.0->-r requirements.txt (line 4)) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium>=4.15.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium>=4.15.0->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium>=4.15.0->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium>=4.15.0->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager>=4.0.0->-r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\roaming\\python\\python311\\site-packages (from webdriver-manager>=4.0.0->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium>=4.15.0->-r requirements.txt (line 4)) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium>=4.15.0->-r requirements.txt (line 4)) (0.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923af16",
   "metadata": {},
   "source": [
    "#### **Import các thư viện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051d3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d5cc4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **2.1 Thiết lập các tham số**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ed209",
   "metadata": {},
   "source": [
    "Khởi tạo Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cb916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d7a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd70ce",
   "metadata": {},
   "source": [
    "\n",
    "Đây là **header HTTP mặc định** được dùng khi gửi request tới các trang web (FBref, Transfermarkt) để giả lập trình duyệt thật, tránh bị chặn.  \n",
    "Các trường quan trọng:\n",
    "\n",
    "- `User-Agent`: Giả lập trình duyệt Chrome trên Windows.\n",
    "- `Accept`: Các định dạng dữ liệu chấp nhận từ server.\n",
    "- `Accept-Language`: Ngôn ngữ ưu tiên.\n",
    "- `Accept-Encoding`: Chấp nhận dữ liệu nén gzip, br.\n",
    "- `Connection`: Giữ kết nối TCP mở.\n",
    "- `Upgrade-Insecure-Requests`: Yêu cầu nâng cấp HTTP → HTTPS nếu có."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SCHEMA = {\n",
    "    \"player_id\": None,\n",
    "    \"player_name\": None,\n",
    "    \"age\": None,\n",
    "    \"nationality\": None,\n",
    "    \"height\": None,\n",
    "    \"foot\": None,\n",
    "    \"position\": None,\n",
    "    \"current_club\": None,\n",
    "    \"league\": None,\n",
    "    \"market_value\": None,\n",
    "\n",
    "    \"appearances\": 0,\n",
    "    \"minutes_played\": 0,\n",
    "    \"minutes_per_game\": 0,\n",
    "\n",
    "    \"goals\": 0,\n",
    "    \"assists\": 0,\n",
    "    \"goals_per_90\": None,\n",
    "    \"assists_per_90\": None,\n",
    "\n",
    "    \"shots\": 0,\n",
    "    \"shots_on_target\": 0,\n",
    "    \"xG\": None,\n",
    "    \"xAG\": None,\n",
    "\n",
    "    \"key_passes\": 0,\n",
    "    \"tackles\": 0,\n",
    "    \"interceptions\": 0,\n",
    "    \"clearances\": 0,\n",
    "    \"aerial_wins\": 0,\n",
    "    \"aerial_win_rate\": None,\n",
    "\n",
    "    \"clean_sheets\": 0,\n",
    "    \"saves\": 0,\n",
    "    \"save_percentage\": None,\n",
    "    \"goals_conceded\": 0,\n",
    "    \"goals_conceded_per_90\": None,\n",
    "    \"psxg_minus_ga\": None,\n",
    "\n",
    "    \"passes_completed\": 0,\n",
    "    \"pass_accuracy\": None,\n",
    "    \"progressive_passes\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad43019c",
   "metadata": {},
   "source": [
    "Đây là cấu trúc dữ liệu chuẩn cho mỗi cầu thủ mà crawler sẽ lưu.\n",
    "\n",
    "Dùng để đảm bảo tất cả cầu thủ đều có cùng trường dữ liệu.\n",
    "\n",
    "Bao gồm thông tin cá nhân, thống kê thi đấu, các chỉ số per-90, thống kê phòng ngự, thủ môn, passing, và giá trị thị trường.\n",
    "\n",
    "Các nhóm dữ liệu chính:\n",
    "\n",
    "- Thông tin cơ bản: `player_id`, `player_name`, `age`, `nationality`, `height`, `foot`, `position`, `current_club`, `league`, `market_value`.\n",
    "\n",
    "- Thống kê thi đấu tổng quát: `appearances`, `minutes_played`, `minutes_per_game`, `goals`, `assists`, `goals_per_90`, `assists_per_90`, `shots`, `shots_on_target`, `xG`, `xAG`, `key_passes`.\n",
    "\n",
    "- Thống kê phòng ngự: `tackles`, `interceptions`, `clearances`, `aerial_wins`, `aerial_win_rate`.\n",
    "\n",
    "- Thống kê thủ môn: `clean_sheets`, `saves`, `save_percentage`, `goals_conceded`, `goals_conceded_per_90`, `psxg_minus_ga`.\n",
    "\n",
    "- Thống kê passing: `passes_completed`, `pass_accuracy`, `progressive_passes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d64218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON = \"2024-2025\"\n",
    "\n",
    "LEAGUE_CONFIG = {\n",
    "    \"La Liga\": f\"https://fbref.com/en/comps/12/{SEASON}/{SEASON}-La-Liga-Stats\",\n",
    "    \"Premier League\": f\"https://fbref.com/en/comps/9/{SEASON}/{SEASON}-Premier-League-Stats\",\n",
    "    \"Serie A\": f\"https://fbref.com/en/comps/11/{SEASON}/{SEASON}-Serie-A-Stats\",\n",
    "    \"Bundesliga\": f\"https://fbref.com/en/comps/20/{SEASON}/{SEASON}-Bundesliga-Stats\",\n",
    "    \"Ligue 1\": f\"https://fbref.com/en/comps/13/{SEASON}/{SEASON}-Ligue-1-Stats\",\n",
    "    \"Eredivisie\": f\"https://fbref.com/en/comps/23/{SEASON}/{SEASON}-Eredivisie-Stats\",\n",
    "    \"Primeira Liga\": f\"https://fbref.com/en/comps/32/{SEASON}/{SEASON}-Primeira-Liga-Stats\",\n",
    "    \"J1 League\": \"https://fbref.com/en/comps/25/J1-League-Stats\",\n",
    "    \"MLS\": \"https://fbref.com/en/comps/22/Major-League-Soccer-Stats\",\n",
    "    \"Belgian Pro League\": f\"https://fbref.com/en/comps/37/{SEASON}/{SEASON}-Belgian-Pro-League-Stats\",\n",
    "    \"Süper Lig\": f\"https://fbref.com/en/comps/26/{SEASON}/{SEASON}-Super-Lig-Stats\",\n",
    "    \"Scottish Premiership\": f\"https://fbref.com/en/comps/40/{SEASON}/{SEASON}-Scottish-Premiership-Stats\",\n",
    "    \"Argentine Liga\": f\"https://fbref.com/en/comps/21/Liga-Profesional-Argentina-Stats\",\n",
    "    \"Liga MX\": f\"https://fbref.com/en/comps/31/{SEASON}/{SEASON}-Liga-MX-Stats\",\n",
    "    \"Eliteserien\": f\"https://fbref.com/en/comps/28/2024/2024-Eliteserien-Stats\",\n",
    "    \"Serbian SuperLiga\": f\"https://fbref.com/en/comps/54/{SEASON}/{SEASON}-Serbian-SuperLiga-Stats\",\n",
    "    \"Russian Premier League\": f\"https://fbref.com/en/comps/30/{SEASON}/{SEASON}-Russian-Premier-League-Stats\",\n",
    "    \"Hrvatska NL\": f\"https://fbref.com/en/comps/63/{SEASON}/{SEASON}-Hrvatska-NL-Stats\",\n",
    "    \"Czech First League\": f\"https://fbref.com/en/comps/66/{SEASON}/{SEASON}-Czech-First-League-Stats\",\n",
    "    \"Chinese Super League\": f\"https://fbref.com/en/comps/62/Chinese-Super-League-Stats\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac2bf0c",
   "metadata": {},
   "source": [
    "`SEASON`: mùa giải muốn lấy dữ liệu (2024-2025).\n",
    "\n",
    "`LEAGUE_CONFIG`: URL mặc định cho từng giải đấu lớn trên FBref.\n",
    "\n",
    "Mỗi key là tên giải, value là URL thống kê của mùa giải đó.\n",
    "\n",
    "Sử dụng f-string để tự động cập nhật mùa giải."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b8fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFERMARKT_PLAYER_SEACH_URL = \"https://www.transfermarkt.com/schnellsuche/ergebnis/schnellsuche?query={player_name}\"\n",
    "MAX_THREADS = 1\n",
    "MIN_DELAY = 1.5\n",
    "MAX_DELAY = 3.0\n",
    "DATA_FOLDER = \"data\"\n",
    "CSV_FOLDER = f\"{DATA_FOLDER}/csv\"\n",
    "JSON_FOLDER = f\"{DATA_FOLDER}/json\"\n",
    "HEADLESS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70eeb1b",
   "metadata": {},
   "source": [
    "Cấu hình delay và folder lưu dữ liệu\n",
    "\n",
    "`DELAY_BETWEEN_REQUESTS`, `DELAY_BETWEEN_PLAYERS`: tránh bị server block bằng cách chèn delay.\n",
    "\n",
    "`TRANSFERMARKT_PLAYER_SEACH_URL`: URL tìm kiếm nhanh cầu thủ trên Transfermarkt.\n",
    "\n",
    "`MAX_THREADS`: số luồng crawl đồng thời.\n",
    "\n",
    "`MIN_DELAY` / `MAX_DELAY`: delay ngẫu nhiên giữa các request.\n",
    "\n",
    "`DATA_FOLDER`, `CSV_FOLDER`, `JSON_FOLDER`: thư mục lưu trữ dữ liệu.\n",
    "\n",
    "`HEADLESS`: chạy Chrome ở chế độ headless (không hiện GUI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e875fb",
   "metadata": {},
   "source": [
    "### **2.2 Hàm hỗ trợ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646404e",
   "metadata": {},
   "source": [
    "Hàm `get_random_delay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b71ac2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_delay(a: float = MIN_DELAY, b: float = MAX_DELAY) -> None:\n",
    "    \"\"\"\n",
    "    Pause execution for a random amount of time between `a` and `b` seconds.\n",
    "\n",
    "    This is useful to mimic human-like behavior in scripts and avoid\n",
    "    triggering rate limits when making repeated requests to APIs or websites.\n",
    "\n",
    "    Args:\n",
    "        a (float): Minimum number of seconds to sleep. Defaults to MIN_DELAY.\n",
    "        b (float): Maximum number of seconds to sleep. Defaults to MAX_DELAY.\n",
    "    \"\"\"\n",
    "    time.sleep(random.uniform(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb45e9",
   "metadata": {},
   "source": [
    "Hàm `generate_player_id`: tạo ID duy nhất cho cầu thủ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10695f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_player_id(player_name: str, dob: Optional[str] = None, nationality: Optional[str] = None) -> str:\n",
    "    name = unicodedata.normalize(\"NFKD\", player_name)\n",
    "    name = name.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    name = re.sub(r\"[^\\w\\s-]\", \"\", name.lower())\n",
    "    name = re.sub(r\"[-\\s]+\", \"-\", name).strip(\"-\")\n",
    "    hash_input = f\"{player_name}:{dob or ''}:{nationality or ''}\"\n",
    "    hash_suffix = hashlib.md5(hash_input.encode(\"utf-8\")).hexdigest()[:6]\n",
    "    return f\"{name}-{hash_suffix}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff77895",
   "metadata": {},
   "source": [
    "Hàm `clean_number`: chuẩn hóa số liệu từ text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26292efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_number(val, allow_float: bool = True):\n",
    "    \"\"\"\n",
    "    Convert string or number to numeric value, handling commas, %, empty strings.\n",
    "\n",
    "    Args:\n",
    "        val: Input value to convert\n",
    "        allow_float (bool): Whether to allow float conversion\n",
    "\n",
    "    Returns:\n",
    "        int or float: Converted numeric value, defaults to 0 on failure\n",
    "    \"\"\"\n",
    "    if val is None:\n",
    "        return 0\n",
    "    try:\n",
    "        s = str(val).strip().replace(\",\", \"\").replace(\"%\", \"\")\n",
    "        if s == \"\":\n",
    "            return 0\n",
    "        if allow_float and (\n",
    "            \".\" in s or s.replace(\".\", \"\", 1).replace(\"-\", \"\", 1).isdigit()\n",
    "        ):\n",
    "            return float(s)\n",
    "        return int(float(s))\n",
    "    except Exception:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b2537",
   "metadata": {},
   "source": [
    "Hàm `find_table_in_comments` tìm bảng ẩn trong comment HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4171ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_table_in_comments(\n",
    "    soup: BeautifulSoup, needle: Optional[str] = None, id_contains: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Find a table that is hidden inside HTML comments.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML page\n",
    "        needle (Optional[str]): Text to match in comment\n",
    "        id_contains (Optional[str]): Substring to match in table id\n",
    "\n",
    "    Returns:\n",
    "        Tag or None: The first matching table element\n",
    "    \"\"\"\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for c in comments:\n",
    "        if needle and needle not in c:\n",
    "            continue\n",
    "        try:\n",
    "            s2 = BeautifulSoup(c, \"html.parser\")\n",
    "            t = (\n",
    "                s2.find(\"table\", id=lambda x: x and id_contains in x)\n",
    "                if id_contains\n",
    "                else s2.find(\"table\")\n",
    "            )\n",
    "            if t:\n",
    "                return t\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef28fc",
   "metadata": {},
   "source": [
    "Hàm `parse_market_value` chuyển giá trị market value từ string dạng '700k', '3.8m' thành float (triệu euro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded4cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_market_value(value_str: str) -> float | None:\n",
    "    \"\"\"\n",
    "    Chuyển giá trị market value từ string dạng '700k', '3.8m' thành float (triệu euro)\n",
    "    \"\"\"\n",
    "    if not value_str:\n",
    "        return None\n",
    "    value_str = value_str.lower().replace(\"€\", \"\").strip()\n",
    "    try:\n",
    "        if value_str.endswith(\"k\"):\n",
    "            return float(value_str[:-1].replace(\",\", \".\")) / 1000\n",
    "        elif value_str.endswith(\"m\"):\n",
    "            return float(value_str[:-1].replace(\",\", \".\"))\n",
    "        else:\n",
    "            # Nếu là số nguyên không có k/m, giả sử là euro, chuyển sang triệu\n",
    "            return float(value_str.replace(\",\", \".\")) / 1_000_000\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc0bc78",
   "metadata": {},
   "source": [
    "Hàm `save_to_csv` lưu tất cả dữ liệu cầu thủ đã thu thập vào file CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112dc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(self, filename: str) -> None:\n",
    "        \"\"\"Save all scraped players to CSV\"\"\"\n",
    "        if not self.players:\n",
    "            logging.warning(\"No players to save\")\n",
    "            return\n",
    "\n",
    "        with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=list(BASE_SCHEMA.keys()))\n",
    "            writer.writeheader()\n",
    "\n",
    "            for player in self.players:\n",
    "                row = {k: player.get(k, BASE_SCHEMA[k]) for k in BASE_SCHEMA.keys()}\n",
    "                writer.writerow(row)\n",
    "\n",
    "        logging.info(f\"Saved {len(self.players)} players to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8840b",
   "metadata": {},
   "source": [
    "Hàm `combine_csv`: gộp tất cả các file CSV trong một thư mục thành một file CSV duy nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3a925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(folder_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Combine all CSV files in a specified folder into a single CSV file.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing the CSV files.\n",
    "        output_path (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"Cannot find any CSV files in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    df_list = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Successfully merged {len(csv_files)} files into: {output_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368d8500",
   "metadata": {},
   "source": [
    "### **2.3 Hàm thu thập dữ liệu (Scraping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab2f46",
   "metadata": {},
   "source": [
    "Hàm `get_market_value`: lấy **giá trị thị trường của cầu thủ** từ *Transfermarkt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55f724c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_value(player_name: str) -> float | None:\n",
    "    \"\"\"\n",
    "    Fetch the market value of a player from Transfermarkt and return as float (million €).\n",
    "\n",
    "    Args:\n",
    "        player_name (str): Full name of the player.\n",
    "\n",
    "    Returns:\n",
    "        float | None: Market value in million €, or None if not found.\n",
    "    \"\"\"\n",
    "    url = TRANSFERMARKT_PLAYER_SEACH_URL.format(player_name=player_name)\n",
    "    logging.info(f\"Fetching market value for {player_name}: {url}\")\n",
    "\n",
    "    resp = requests.get(url, headers=HEADERS)\n",
    "    random_delay()\n",
    "    if resp.status_code != 200:\n",
    "        logging.warning(f\"Failed to load page for {player_name}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"items\")\n",
    "    if not table:\n",
    "        logging.warning(f\"No search results table found for {player_name}\")\n",
    "        return None\n",
    "\n",
    "    for row in table.tbody.find_all(\"tr\"):\n",
    "        mv_tag = row.find(\"td\", class_=\"rechts hauptlink\")\n",
    "        if mv_tag:\n",
    "            market_value_str = mv_tag.get_text(strip=True).replace(\"€\", \"\").strip()\n",
    "            return parse_market_value(market_value_str)\n",
    "\n",
    "    logging.warning(f\"Player {player_name} not found\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16e1b2",
   "metadata": {},
   "source": [
    "Hàm `get_profile_url` dùng **Selenium WebDriver** để **lấy URL hồ sơ cầu thủ trên Transfermarkt**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf01329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_url(driver, player_name: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Get the Transfermarkt profile URL of a player using a Selenium driver.\n",
    "\n",
    "    Args:\n",
    "        driver: Selenium WebDriver instance.\n",
    "        player_name (str): Full name of the player.\n",
    "\n",
    "    Returns:\n",
    "        str | None: Player profile URL, or None if not found.\n",
    "    \"\"\"\n",
    "    search_url = TRANSFERMARKT_PLAYER_SEACH_URL.format(player_name=player_name)\n",
    "    driver.get(search_url)\n",
    "    random_delay(2, 4)\n",
    "\n",
    "    try:\n",
    "        td = driver.find_element(By.CSS_SELECTOR, \"td.hauptlink a\")\n",
    "        href = td.get_attribute(\"href\")\n",
    "        logging.info(f\"{player_name}: URL found: {href}\")\n",
    "        return href\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"{player_name}: URL not found: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f76e8b",
   "metadata": {},
   "source": [
    "Hàm `get_height` dùng để **lấy chiều cao của cầu thủ** từ trang hồ sơ *Transfermark* để phòng trường hợp *Fbref* không có thông tin này.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b1a2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_height(player_url: str, player_name: str) -> int | None:\n",
    "    \"\"\"\n",
    "    Fetch the height of a player from their Transfermarkt profile.\n",
    "\n",
    "    Args:\n",
    "        player_url (str): URL of the player's Transfermarkt profile.\n",
    "        player_name (str): Full name of the player.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Height in centimeters, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = requests.get(player_url, headers=HEADERS, timeout=10)\n",
    "        random_delay()\n",
    "        if resp.status_code != 200:\n",
    "            logging.warning(\n",
    "                f\"{player_name} -> Failed to load profile page ({resp.status_code})\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        details_div = soup.find(\"div\", class_=\"data-header__details\")\n",
    "        if not details_div:\n",
    "            logging.warning(f\"{player_name} -> Details div not found\")\n",
    "            return None\n",
    "\n",
    "        # Look for the <li> containing \"Height\" and extract the value\n",
    "        for li in details_div.find_all(\"li\"):\n",
    "            if \"Height\" in li.get_text():\n",
    "                span = li.find(\"span\", itemprop=\"height\")\n",
    "                if span:\n",
    "                    height_text = span.get_text(strip=True)\n",
    "                    match = re.search(r\"([\\d,]+)\\s*m\", height_text)\n",
    "                    if match:\n",
    "                        height_m = match.group(1).replace(\",\", \".\")\n",
    "                        height_cm = int(float(height_m) * 100)\n",
    "                        logging.info(f\"{player_name}: Height: {height_cm} cm\")\n",
    "                        return height_cm\n",
    "\n",
    "        logging.warning(f\"{player_name}: Height not found\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"{player_name}: Error fetching height: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d5f255",
   "metadata": {},
   "source": [
    "Định nghĩa lớp FootballPlayerCrawler\n",
    "- Đây là lớp chính để crawl dữ liệu cầu thủ\n",
    "- Bao gồm: mở trình duyệt, truy cập trang, scrape cầu thủ, tính toán thống kê, lưu CSV/JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54081faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FootballPlayerCrawler:\n",
    "    def __init__(self, headless: bool = True, user_agent: Optional[str] = None):\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless=new\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        ua = user_agent or \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "        chrome_options.add_argument(f\"user-agent={ua}\")\n",
    "\n",
    "        # Bỏ ChromeDriverManager, để Selenium tự quản lý\n",
    "        self.driver = webdriver.Chrome(options=chrome_options)\n",
    "        self.players: List[Dict] = []\n",
    "        self.seen_ids: Set[str] = set()\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb): \n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18d8c4",
   "metadata": {},
   "source": [
    "Hàm lấy trang và parse **BeautifulSoup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6912aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_soup(self, url: str, wait: float = 1.5) -> Optional[BeautifulSoup]:\n",
    "        logging.info(f\"GET {url}\")\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to load {url}: {e}\")\n",
    "            return None\n",
    "        random_delay(wait, wait + 1.0)\n",
    "        return BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "\n",
    "FootballPlayerCrawler.get_page_soup = get_page_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dbc00",
   "metadata": {},
   "source": [
    "Hàm lấy danh sách câu lạc bộ trong giải đấu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee6a1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_league_clubs(self, league_url: str) -> List[Dict[str, str]]:\n",
    "    soup = self.get_page_soup(league_url)\n",
    "    if not soup:\n",
    "        return []\n",
    "\n",
    "    table = soup.find(\"table\", class_=\"stats_table\")\n",
    "    if not table:\n",
    "        table = find_table_in_comments(soup, needle=\"standings\")\n",
    "\n",
    "    clubs = []\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "        if tbody:\n",
    "            for row in tbody.find_all(\"tr\"):\n",
    "                team_cell = row.find(\"td\", {\"data-stat\": \"team\"})\n",
    "                if team_cell:\n",
    "                    a = team_cell.find(\"a\")\n",
    "                    if a and a.get(\"href\"):\n",
    "                        clubs.append({\"club_name\": a.get_text(strip=True),\n",
    "                                        \"club_url\": \"https://fbref.com\" + a[\"href\"]})\n",
    "    logging.info(f\"Found {len(clubs)} clubs\")\n",
    "    return clubs\n",
    "\n",
    "FootballPlayerCrawler.get_league_clubs = get_league_clubs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c89c3",
   "metadata": {},
   "source": [
    " Hàm lấy danh sách cầu thủ của câu lạc bộ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49dc0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_club_players(self, club_url: str) -> List[Dict]:\n",
    "    soup = self.get_page_soup(club_url)\n",
    "    if not soup:\n",
    "        return []\n",
    "\n",
    "    table = soup.find(\"table\", id=lambda v: v and v.startswith(\"stats_standard\"))\n",
    "    if not table:\n",
    "        table = find_table_in_comments(soup, needle=\"stats_standard\")\n",
    "\n",
    "    players = []\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "        if tbody:\n",
    "            for row in tbody.find_all(\"tr\"):\n",
    "                if row.get(\"class\") and \"thead\" in row.get(\"class\"):\n",
    "                    continue\n",
    "                th = row.find(\"th\", {\"data-stat\": \"player\"})\n",
    "                if not th:\n",
    "                    continue\n",
    "                a = th.find(\"a\")\n",
    "                if not a or not a.get(\"href\"):\n",
    "                    continue\n",
    "                def get_stat(col, allow_float=True):\n",
    "                    td = row.find(\"td\", {\"data-stat\": col})\n",
    "                    return clean_number(td.text if td else None, allow_float=allow_float)\n",
    "                players.append({\n",
    "                    \"player_name\": a.get_text(strip=True),\n",
    "                    \"player_url\": \"https://fbref.com\" + a[\"href\"],\n",
    "                    \"appearances\": get_stat(\"games\", allow_float=False),\n",
    "                    \"minutes_played\": get_stat(\"minutes\", allow_float=False),\n",
    "                    \"goals\": get_stat(\"goals\", allow_float=False),\n",
    "                    \"assists\": get_stat(\"assists\", allow_float=False),\n",
    "                    \"xG\": get_stat(\"xg\"),\n",
    "                    \"xAG\": get_stat(\"xg_assist\"),\n",
    "                })\n",
    "    logging.info(f\"Found {len(players)} players\")\n",
    "    return players\n",
    "\n",
    "FootballPlayerCrawler.get_club_players = get_club_players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf10a3",
   "metadata": {},
   "source": [
    "Hàm dùng để **thu thập đầy đủ dữ liệu cầu thủ** từ trang FBref, bao gồm thông tin cơ bản, thống kê thi đấu, phòng ngự, passing, thủ môn và giá trị thị trường.\n",
    "\n",
    "1. Lấy **HTML soup** từ URL cầu thủ.  \n",
    "2. Khởi tạo dictionary `stats` theo `BASE_SCHEMA`.  \n",
    "3. Lấy các thông tin cơ bản:\n",
    "   - `player_name`: tên cầu thủ.\n",
    "   - `nationality`: quốc tịch.\n",
    "   - `age`: tuổi tính từ ngày sinh.\n",
    "   - `player_id`: ID duy nhất được sinh tự động.\n",
    "   - `height`: chiều cao (cm), có fallback dùng Selenium nếu không tìm thấy trong trang.  \n",
    "   - `position` & `foot`: vị trí và chân thuận.\n",
    "4. Gọi các hàm `_parse_*_stats` để lấy thống kê:\n",
    "   - `_parse_standard_stats`: thống kê tổng quát (games, minutes, goals…).  \n",
    "   - `_parse_defensive_stats`: thống kê phòng ngự (tackles, interceptions…).  \n",
    "   - `_parse_passing_stats`: thống kê chuyền bóng (passes_completed, pass_accuracy…).  \n",
    "   - `_parse_goalkeeper_stats`: thống kê thủ môn (saves, clean_sheets…).  \n",
    "   - `_calculate_derived_fields`: tính các trường dẫn xuất như `goals_per_90`.  \n",
    "5. Lấy giá trị thị trường cầu thủ từ Transfermarkt bằng `get_market_value`.  \n",
    "6. Trả về dictionary `stats` hoàn chỉnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc3a3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_full_players_data(\n",
    "    self,\n",
    "    player_url: str,\n",
    "    league_name: Optional[str] = None,\n",
    "    club_name: Optional[str] = None,\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Scrape complete player profile with all statistics\n",
    "    \"\"\"\n",
    "    soup = self.get_page_soup(player_url)\n",
    "    if not soup:\n",
    "        return None\n",
    "\n",
    "    stats = dict(BASE_SCHEMA)\n",
    "    stats[\"league\"] = league_name or \"\"\n",
    "    stats[\"current_club\"] = club_name or \"\"\n",
    "\n",
    "    # Get HTML main container\n",
    "    info_div = soup.find(\"div\", id=\"info\")\n",
    "    if not info_div:\n",
    "        return stats\n",
    "\n",
    "    # --- Player name ---\n",
    "    h1 = info_div.find(\"h1\")\n",
    "    if h1:\n",
    "        stats[\"player_name\"] = h1.get_text(strip=True)\n",
    "\n",
    "    # --- Nationality ---\n",
    "    nat_link = info_div.find(\"a\", href=lambda x: x and \"/country/\" in x)\n",
    "    if nat_link:\n",
    "        stats[\"nationality\"] = nat_link.get_text(strip=True)\n",
    "\n",
    "    # --- Date of birth & age ---\n",
    "    dob = None\n",
    "    birth_span = info_div.find(\"span\", id=\"necro-birth\")\n",
    "    if birth_span and birth_span.get(\"data-birth\"):\n",
    "        dob = birth_span[\"data-birth\"]\n",
    "        try:\n",
    "            dt = datetime.strptime(dob, \"%Y-%m-%d\")\n",
    "            today = datetime.today()\n",
    "            stats[\"age\"] = (\n",
    "                today.year\n",
    "                - dt.year\n",
    "                - ((today.month, today.day) < (dt.month, dt.day))\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # --- Generate unique player ID ---\n",
    "    player_id = generate_player_id(\n",
    "        stats.get(\"player_name\"), dob=dob, nationality=stats.get(\"nationality\")\n",
    "    )\n",
    "    counter = 1\n",
    "    base_id = player_id\n",
    "    while player_id in self.seen_ids:\n",
    "        player_id = f\"{base_id}-{counter}\"\n",
    "        counter += 1\n",
    "    self.seen_ids.add(player_id)\n",
    "    stats[\"player_id\"] = player_id\n",
    "\n",
    "    # --- Height ---\n",
    "    height_span = info_div.find(\"span\", string=lambda s: s and s.endswith(\"cm\"))\n",
    "    if height_span:\n",
    "        try:\n",
    "            stats[\"height\"] = float(\n",
    "                height_span.get_text(strip=True).replace(\"cm\", \"\").strip()\n",
    "            )\n",
    "        except:\n",
    "            stats[\"height\"] = None\n",
    "    else:\n",
    "\n",
    "        if stats.get(\"player_name\") and stats.get(\"current_club\"):\n",
    "            try:\n",
    "                profile_url = get_profile_url(self.driver, stats[\"player_name\"])\n",
    "                if profile_url:\n",
    "                    height_cm = get_height(profile_url, stats[\"player_name\"])\n",
    "                    stats[\"height\"] = height_cm\n",
    "                else:\n",
    "                    stats[\"height\"] = None\n",
    "            except Exception as e:\n",
    "                logging.warning(\n",
    "                    f\"{stats['player_name']}: Cannot get height from fallback: {e}\"\n",
    "                )\n",
    "                stats[\"height\"] = None\n",
    "\n",
    "    # --- Position & Footed ---\n",
    "    info_text = info_div.get_text(\" \", strip=True).replace(\"\\xa0\", \" \")\n",
    "\n",
    "    m_pos = re.search(r\"Position:\\s*([A-Za-z0-9\\-]+)\", info_text)\n",
    "    m_foot = re.search(r\"Footed:\\s*([A-Za-z]+)\", info_text)\n",
    "\n",
    "    if m_pos:\n",
    "        stats[\"position\"] = m_pos.group(1).strip()\n",
    "    if m_foot:\n",
    "        stats[\"foot\"] = m_foot.group(1).strip()\n",
    "\n",
    "    # --- Parse stats tables ---\n",
    "    self._parse_standard_stats(soup, stats)\n",
    "    self._parse_defensive_stats(soup, stats)\n",
    "    self._parse_passing_stats(soup, stats)\n",
    "    self._parse_goalkeeper_stats(soup, stats)\n",
    "    self._calculate_derived_fields(stats)\n",
    "\n",
    "    # --- Market value ---\n",
    "    try:\n",
    "        stats[\"market_value\"] = get_market_value(player_name=stats[\"player_name\"])\n",
    "    except Exception as e:\n",
    "        logging.warning(\n",
    "            f\"Can not get market value for {stats.get('player_name')}: {e}\"\n",
    "        )\n",
    "        stats[\"market_value\"] = None\n",
    "\n",
    "    return stats\n",
    "\n",
    "FootballPlayerCrawler.scrape_full_players_data = scrape_full_players_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e1d4f",
   "metadata": {},
   "source": [
    "Các hàm `_parse_*_stats`\n",
    "\n",
    "`_parse_standard_stats`\n",
    "- Parse bảng thống kê tổng quát của cầu thủ.\n",
    "- Lấy các thông số như: `appearances`, `minutes_played`, `goals`, `assists`, `shots`, `shots_on_target`, `xG`, `xAG`, `passes_completed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24f3c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_standard_stats(self, soup: BeautifulSoup, stats: Dict) -> None:\n",
    "        \"\"\"Parse standard statistics table\"\"\"\n",
    "        std_table = soup.find(\n",
    "            \"table\", id=lambda x: x and x.startswith(\"stats_standard\")\n",
    "        )\n",
    "        if not std_table:\n",
    "            std_table = find_table_in_comments(soup, needle=\"stats_standard\")\n",
    "\n",
    "        if std_table:\n",
    "            tbody = std_table.find(\"tbody\")\n",
    "            if tbody:\n",
    "                agg = {}\n",
    "                mapping = {\n",
    "                    \"games\": \"appearances\",\n",
    "                    \"minutes\": \"minutes_played\",\n",
    "                    \"goals\": \"goals\",\n",
    "                    \"assists\": \"assists\",\n",
    "                    \"shots\": \"shots\",\n",
    "                    \"shots_on_target\": \"shots_on_target\",\n",
    "                    \"xg\": \"xG\",\n",
    "                    \"xg_assist\": \"xAG\",\n",
    "                    \"passes_completed\": \"passes_completed\",\n",
    "                }\n",
    "\n",
    "                for row in tbody.find_all(\"tr\"):\n",
    "                    if row.get(\"class\") and \"thead\" in row.get(\"class\"):\n",
    "                        continue\n",
    "\n",
    "                    for td in row.find_all(\"td\"):\n",
    "                        dstat = td.get(\"data-stat\")\n",
    "                        if dstat in mapping:\n",
    "                            key = mapping[dstat]\n",
    "                            is_int = key in [\n",
    "                                \"appearances\",\n",
    "                                \"minutes_played\",\n",
    "                                \"goals\",\n",
    "                                \"assists\",\n",
    "                                \"shots\",\n",
    "                                \"shots_on_target\",\n",
    "                                \"passes_completed\",\n",
    "                            ]\n",
    "                            val = clean_number(\n",
    "                                td.get_text(strip=True), allow_float=not is_int\n",
    "                            )\n",
    "                            agg[key] = agg.get(key, 0) + val\n",
    "\n",
    "                for k, v in agg.items():\n",
    "                    stats[k] = v\n",
    "\n",
    "FootballPlayerCrawler._parse_standard_stats = _parse_standard_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1be8a",
   "metadata": {},
   "source": [
    "`_parse_defensive_stats`\n",
    "- Parse bảng phòng ngự.\n",
    "- Lấy các thông số: `tackles`, `interceptions`, `clearances`, `aerial_wins`, `aerial_win_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ab34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_defensive_stats(self, soup: BeautifulSoup, stats: Dict) -> None:\n",
    "        \"\"\"Parse defensive statistics table\"\"\"\n",
    "        def_table = soup.find(\"table\", id=lambda x: x and \"defense\" in x)\n",
    "        if not def_table:\n",
    "            def_table = find_table_in_comments(soup, needle=\"Defense\")\n",
    "\n",
    "        if def_table:\n",
    "            tbody = def_table.find(\"tbody\")\n",
    "            if tbody:\n",
    "                for row in tbody.find_all(\"tr\"):\n",
    "                    if row.get(\"class\") and \"thead\" in row.get(\"class\"):\n",
    "                        continue\n",
    "\n",
    "                    def get_stat(dstat, allow_float=False):\n",
    "                        td = row.find(\"td\", {\"data-stat\": dstat})\n",
    "                        return clean_number(\n",
    "                            td.get_text(strip=True) if td else None,\n",
    "                            allow_float=allow_float,\n",
    "                        )\n",
    "\n",
    "                    if val := get_stat(\"tackles\"):\n",
    "                        stats[\"tackles\"] = val\n",
    "                    if val := get_stat(\"interceptions\"):\n",
    "                        print(f\"Pedri: \")\n",
    "                        stats[\"interceptions\"] = val\n",
    "                    if val := get_stat(\"clearances\"):\n",
    "                        stats[\"clearances\"] = val\n",
    "                    if val := get_stat(\"aerials_won\"):\n",
    "                        stats[\"aerial_wins\"] = val\n",
    "                    if val := get_stat(\"aerials_won_pct\", allow_float=True):\n",
    "                        stats[\"aerial_win_rate\"] = val\n",
    "\n",
    "FootballPlayerCrawler._parse_defensive_stats = _parse_defensive_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c10b5",
   "metadata": {},
   "source": [
    "`_parse_passing_stats`\n",
    "- Parse bảng chuyền bóng.\n",
    "- Lấy các thông số: `passes_completed`, `pass_accuracy`, `progressive_passes`, `key_passes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f02bd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_passing_stats(self, soup: BeautifulSoup, stats: Dict) -> None:\n",
    "    \"\"\"Parse passing statistics table\"\"\"\n",
    "    pass_table = soup.find(\"table\", id=lambda x: x and \"passing\" in x)\n",
    "    if not pass_table:\n",
    "        pass_table = find_table_in_comments(soup, needle=\"Passes\")\n",
    "\n",
    "    if pass_table:\n",
    "        tbody = pass_table.find(\"tbody\")\n",
    "        if tbody:\n",
    "            for row in tbody.find_all(\"tr\"):\n",
    "                if row.get(\"class\") and \"thead\" in row.get(\"class\"):\n",
    "                    continue\n",
    "\n",
    "                def get_stat(dstat, allow_float=False):\n",
    "                    td = row.find(\"td\", {\"data-stat\": dstat})\n",
    "                    return clean_number(\n",
    "                        td.get_text(strip=True) if td else None,\n",
    "                        allow_float=allow_float,\n",
    "                    )\n",
    "\n",
    "                if val := get_stat(\"passes_completed\"):\n",
    "                    stats[\"passes_completed\"] = val\n",
    "                if val := get_stat(\"passes_pct\", allow_float=True):\n",
    "                    stats[\"pass_accuracy\"] = val\n",
    "                if val := get_stat(\"progressive_passes\"):\n",
    "                    stats[\"progressive_passes\"] = val\n",
    "                if val := get_stat(\"passes_into_final_third\"):\n",
    "                    stats[\"key_passes\"] = val\n",
    "\n",
    "FootballPlayerCrawler._parse_passing_stats = _parse_passing_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7f9df",
   "metadata": {},
   "source": [
    "`_parse_goalkeeper_stats`\n",
    "- Parse bảng thủ môn.\n",
    "- Lấy các thông số: `saves`, `save_percentage`, `goals_conceded`, `clean_sheets`, `psxg_minus_ga`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eb96bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_goalkeeper_stats(self, soup: BeautifulSoup, stats: Dict) -> None:\n",
    "        \"\"\"Parse goalkeeper statistics table\"\"\"\n",
    "        gk_table = soup.find(\"table\", id=lambda x: x and \"keeper\" in x)\n",
    "        if not gk_table:\n",
    "            gk_table = find_table_in_comments(soup, needle=\"Goalkeeping\")\n",
    "\n",
    "        if gk_table:\n",
    "            tbody = gk_table.find(\"tbody\")\n",
    "            if tbody:\n",
    "                for row in tbody.find_all(\"tr\"):\n",
    "                    if row.get(\"class\") and \"thead\" in row.get(\"class\"):\n",
    "                        continue\n",
    "\n",
    "                    def get_stat(dstat, allow_float=False):\n",
    "                        td = row.find(\"td\", {\"data-stat\": dstat})\n",
    "                        return clean_number(\n",
    "                            td.get_text(strip=True) if td else None,\n",
    "                            allow_float=allow_float,\n",
    "                        )\n",
    "\n",
    "                    if val := get_stat(\"gk_saves\"):\n",
    "                        stats[\"saves\"] = val\n",
    "                    if val := get_stat(\"gk_save_pct\", allow_float=True):\n",
    "                        stats[\"save_percentage\"] = val\n",
    "                    if val := get_stat(\"gk_goals_against\"):\n",
    "                        stats[\"goals_conceded\"] = val\n",
    "                    if val := get_stat(\"gk_clean_sheets\"):\n",
    "                        stats[\"clean_sheets\"] = val\n",
    "                    if val := get_stat(\"gk_psxg_gk\", allow_float=True):\n",
    "                        stats[\"psxg_minus_ga\"] = val\n",
    "\n",
    "FootballPlayerCrawler._parse_goalkeeper_stats = _parse_goalkeeper_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9250da9",
   "metadata": {},
   "source": [
    "`_calculate_derived_fields`\n",
    "\n",
    "Tính các chỉ số dẫn xuất:\n",
    "- `minutes_per_game` = `minutes_played` / `appearances`\n",
    "- `goals_per_90`, `assists_per_90` = chuẩn hóa trên 90 phút\n",
    "- `goals_conceded_per_90` = chuẩn hóa cho thủ môn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccdcded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_derived_fields(self, stats: Dict) -> None:\n",
    "        \"\"\"Calculate per-90 and other derived statistics\"\"\"\n",
    "        if stats[\"minutes_played\"] and stats[\"appearances\"]:\n",
    "            stats[\"minutes_per_game\"] = round(\n",
    "                stats[\"minutes_played\"] / max(1, stats[\"appearances\"]), 1\n",
    "            )\n",
    "\n",
    "        if stats[\"minutes_played\"] > 0:\n",
    "            mins_90 = stats[\"minutes_played\"] / 90\n",
    "            stats[\"goals_per_90\"] = round(stats[\"goals\"] / mins_90, 2)\n",
    "            stats[\"assists_per_90\"] = round(stats[\"assists\"] / mins_90, 2)\n",
    "\n",
    "            if stats[\"goals_conceded\"]:\n",
    "                stats[\"goals_conceded_per_90\"] = round(\n",
    "                    stats[\"goals_conceded\"] / mins_90, 2\n",
    "                )\n",
    "\n",
    "FootballPlayerCrawler._calculate_derived_fields = _calculate_derived_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5bc0a8",
   "metadata": {},
   "source": [
    "Hàm `scrape_league`\n",
    "\n",
    "- Thu thập cầu thủ theo giải đấu **và lưu ngay vào CSV/JSON**.  \n",
    "- Mở file CSV & JSON, ghi header, sau đó duyệt qua các CLB và cầu thủ.  \n",
    "- Merge các thống kê cơ bản từ CLB.  \n",
    "- Ghi dữ liệu ra CSV và JSON từng cầu thủ, flush dữ liệu sau mỗi lần ghi.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3815d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_league(\n",
    "        self,\n",
    "        league_name: str,\n",
    "        league_url: str,\n",
    "        csv_file=None,\n",
    "        json_file=None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Scrape all players in a league and save immediately to CSV/JSON\n",
    "        \"\"\"\n",
    "\n",
    "        if csv_file is None:\n",
    "            csv_file = f\"{league_name.replace(' ', '_').lower()}_players.csv\"\n",
    "        if json_file is None:\n",
    "            json_file = f\"{league_name.replace(' ', '_').lower()}_players.json\"\n",
    "\n",
    "        logging.info(f\"Starting league: {league_name}\")\n",
    "        logging.info(f\"CSV file:  {csv_file}\")\n",
    "        logging.info(f\"JSON file: {json_file}\")\n",
    "\n",
    "        clubs = self.get_league_clubs(league_url)\n",
    "\n",
    "        # Open CSV & JSON once\n",
    "        csv_f = open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "        csv_writer = csv.DictWriter(csv_f, fieldnames=list(BASE_SCHEMA.keys()))\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        json_f = open(json_file, \"w\", encoding=\"utf-8\")\n",
    "        json_f.write(\"[\\n\")\n",
    "        first = True\n",
    "\n",
    "        try:\n",
    "            for club in clubs:\n",
    "                logging.info(f\"Scraping club: {club['club_name']}\")\n",
    "                club_players = self.get_club_players(club[\"club_url\"])\n",
    "\n",
    "                for p in club_players:\n",
    "                    try:\n",
    "                        full = self.scrape_full_players_data(\n",
    "                            p[\"player_url\"], league_name, club[\"club_name\"]\n",
    "                        )\n",
    "                        if not full:\n",
    "                            continue\n",
    "\n",
    "                        # Merge basic stats\n",
    "                        for stat in [\n",
    "                            \"appearances\",\n",
    "                            \"minutes_played\",\n",
    "                            \"goals\",\n",
    "                            \"assists\",\n",
    "                            \"xG\",\n",
    "                            \"xAG\",\n",
    "                        ]:\n",
    "                            full[stat] = p.get(stat) or full.get(stat, 0)\n",
    "\n",
    "                        self._calculate_derived_fields(full)\n",
    "\n",
    "                        # Write CSV\n",
    "                        csv_writer.writerow(\n",
    "                            {k: full.get(k, BASE_SCHEMA[k]) for k in BASE_SCHEMA.keys()}\n",
    "                        )\n",
    "                        csv_f.flush()\n",
    "\n",
    "                        # Write JSON\n",
    "                        if not first:\n",
    "                            json_f.write(\",\\n\")\n",
    "                        else:\n",
    "                            first = False\n",
    "\n",
    "                        json.dump(\n",
    "                            {\n",
    "                                k: full.get(k, BASE_SCHEMA[k])\n",
    "                                for k in BASE_SCHEMA.keys()\n",
    "                            },\n",
    "                            json_f,\n",
    "                            ensure_ascii=False,\n",
    "                            indent=2,\n",
    "                        )\n",
    "                        json_f.flush()\n",
    "\n",
    "                        logging.info(\n",
    "                            f\"✓ {full['player_name']} (ID: {full['player_id']})\"\n",
    "                        )\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.exception(\n",
    "                            f\"✗ Error scraping {p.get('player_name')}: {e}\"\n",
    "                        )\n",
    "\n",
    "        finally:\n",
    "            csv_f.close()\n",
    "            json_f.write(\"\\n]\")\n",
    "            json_f.close()\n",
    "\n",
    "        logging.info(f\"League {league_name} complete.\")\n",
    "\n",
    "\n",
    "FootballPlayerCrawler.scrape_league = scrape_league\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4f59a",
   "metadata": {},
   "source": [
    "### **2.4 Thực thi code để thu thập dữ liệu (Scraping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ae021",
   "metadata": {},
   "source": [
    "Hàm này dùng để **thu thập dữ liệu tất cả cầu thủ trong một giải đấu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "394fbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one_league(args):\n",
    "    league_name, league_url = args\n",
    "    crawler = FootballPlayerCrawler(headless=HEADLESS)\n",
    "\n",
    "    os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "    os.makedirs(JSON_FOLDER, exist_ok=True)\n",
    "\n",
    "    csv_file = os.path.join(CSV_FOLDER, f\"{league_name.replace(' ', '_')}.csv\")\n",
    "    json_file = os.path.join(JSON_FOLDER, f\"{league_name.replace(' ', '_')}.json\")\n",
    "\n",
    "    crawler.scrape_league(\n",
    "        league_name, league_url, csv_file=csv_file, json_file=json_file\n",
    "    )\n",
    "\n",
    "    crawler.close()\n",
    "    return league_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e1b24",
   "metadata": {},
   "source": [
    "Thực hiện craping cầu thủ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c5fddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 17:27:02,156 [INFO] Starting league: La Liga\n",
      "2025-11-29 17:27:02,156 [INFO] CSV file:  data/csv\\La_Liga.csv\n",
      "2025-11-29 17:27:02,157 [INFO] JSON file: data/json\\La_Liga.json\n",
      "2025-11-29 17:27:02,157 [INFO] GET https://fbref.com/en/comps/12/2024-2025/2024-2025-La-Liga-Stats\n",
      "2025-11-29 17:27:09,924 [INFO] Found 20 clubs\n",
      "2025-11-29 17:27:09,927 [INFO] Scraping club: Barcelona\n",
      "2025-11-29 17:27:09,927 [INFO] GET https://fbref.com/en/squads/206d90db/2024-2025/Barcelona-Stats\n",
      "2025-11-29 17:27:13,722 [INFO] Found 39 players\n",
      "2025-11-29 17:27:13,722 [INFO] GET https://fbref.com/en/players/0d9b2d31/Pedri\n",
      "2025-11-29 17:27:17,127 [INFO] Fetching market value for Pedri: https://www.transfermarkt.com/schnellsuche/ergebnis/schnellsuche?query=Pedri\n",
      "2025-11-29 17:27:19,660 [INFO] ✓ Pedri (ID: pedri-d01084)\n",
      "2025-11-29 17:27:19,661 [INFO] GET https://fbref.com/en/players/3423f250/Raphinha\n",
      "2025-11-29 17:27:23,797 [INFO] Fetching market value for Raphinha: https://www.transfermarkt.com/schnellsuche/ergebnis/schnellsuche?query=Raphinha\n",
      "2025-11-29 17:27:26,789 [INFO] ✓ Raphinha (ID: raphinha-f3883d)\n",
      "2025-11-29 17:27:26,790 [INFO] GET https://fbref.com/en/players/8d78e732/Robert-Lewandowski\n",
      "2025-11-29 17:27:31,502 [INFO] Fetching market value for Robert Lewandowski: https://www.transfermarkt.com/schnellsuche/ergebnis/schnellsuche?query=Robert Lewandowski\n",
      "2025-11-29 17:27:34,268 [INFO] ✓ Robert Lewandowski (ID: robert-lewandowski-bd8521)\n",
      "2025-11-29 17:27:34,269 [INFO] GET https://fbref.com/en/players/82ec26c1/Lamine-Yamal\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m league_name, league_url \u001b[38;5;129;01min\u001b[39;00m LEAGUE_CONFIG\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mscrape_one_league\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleague_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleague_url\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m, in \u001b[0;36mscrape_one_league\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m      8\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CSV_FOLDER, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleague_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m json_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(JSON_FOLDER, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleague_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mcrawler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_league\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleague_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleague_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_file\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m crawler\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m league_name\n",
      "Cell \u001b[1;32mIn[28], line 39\u001b[0m, in \u001b[0;36mscrape_league\u001b[1;34m(self, league_name, league_url, csv_file, json_file)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m club_players:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m         full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_full_players_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplayer_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleague_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclub\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclub_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m full:\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 74\u001b[0m, in \u001b[0;36mscrape_full_players_data\u001b[1;34m(self, player_url, league_name, club_name)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m stats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_club\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m         profile_url \u001b[38;5;241m=\u001b[39m \u001b[43mget_profile_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplayer_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m profile_url:\n\u001b[0;32m     76\u001b[0m             height_cm \u001b[38;5;241m=\u001b[39m get_height(profile_url, stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36mget_profile_url\u001b[1;34m(driver, player_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mGet the Transfermarkt profile URL of a player using a Selenium driver.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    str | None: Player profile URL, or None if not found.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m search_url \u001b[38;5;241m=\u001b[39m TRANSFERMARKT_PLAYER_SEACH_URL\u001b[38;5;241m.\u001b[39mformat(player_name\u001b[38;5;241m=\u001b[39mplayer_name)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m random_delay(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    tab.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:455\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    453\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 455\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRemoteConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:407\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    405\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    406\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:431\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    428\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 431\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\poolmanager.py:459\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    457\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for league_name, league_url in LEAGUE_CONFIG.items():\n",
    "    scrape_one_league((league_name, league_url))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
